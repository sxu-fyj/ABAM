ssh://fuyj@115.24.15.21:22/home/fuyj/workspace/venv/torch/bin/python3 -u /home/fuyj/.pycharm_helpers/pydev/pydevd.py --multiproc --qt-support=auto --client 0.0.0.0 --port 42973 --file /home/fuyj/workspace/experiment/ABAM-main/src/run_AURC_synLSTM.py
pydev debugger: process 20793 is connecting

Connected to pydev debugger (build 193.7288.30)
device cuda:0
../models_final/aurc_in_token.pt
../models_final/aurc_in_config.json
../models_final/aurc_in_predictions_dev.json
../models_final/aurc_in_predictions_test.json
../data/../data/data_dict_bert_pieces2word.json
数据集大小
4396
8 ['abortion', 'cloning', 'death penalty', 'gun control', 'marijuana legalization', 'minimum wage', 'nuclear energy', 'school uniforms']
{'abortion': 415, 'cloning': 343, 'death penalty': 588, 'gun control': 480, 'marijuana legalization': 626, 'minimum wage': 624, 'nuclear energy': 615, 'school uniforms': 705}
Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
/home/fuyj/workspace/venv/torch/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,
0
/home/fuyj/workspace/experiment/ABAM-main/src/run_AURC_synLSTM.py:373: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)
  all_pieces2word = torch.tensor([f.pieces2word for f in train_features])
2268 71
307 307
636 636
[Info] Building character-level LSTM
2800
##### DOMAIN: inner , use CRF: True , learning-rate: 1e-05 , DROPOUT: 0.1

Epoch:    0 2022-10-21 10:37:18.508538
/home/fuyj/workspace/venv/torch/lib/python3.6/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
[[11325  4099     0  3012     2]
 [ 1818 11365     0  3074     2]
 [  151  3013     0  1578     2]
 [ 1539  7406     0  7367     8]
 [  108  1794     0  3415     6]]
TRAIN:  Pre. 0.374 | Rec. 0.353 | F1 0.324
[[1354  525    0  414    1]
 [ 253 1669    0  376    1]
 [  18  406    0  208    1]
 [ 210  904    0 1153    2]
 [  18  194    0  477    2]]
EVAL:   Pre. 0.381 | Rec. 0.365 | F1 0.337 | BEST F1: 0.000 None
[[3074 1172    0  845    1]
 [ 608 3276    0  802    3]
 [  64  850    0  404    0]
 [ 575 1997    0 2129    1]
 [  54  439    0 1063    1]]
TEST:   Pre. 0.340 | Rec. 0.351 | F1 0.321

Epoch:    1 2022-10-21 10:38:52.345980
[[12388  3268   314  2057   411]
 [  938 12858   640  1594   229]
 [   94  1875  1999   180   596]
 [  841  6101   331  8354   693]
 [   89   743   975   960  2556]]
TRAIN:  Pre. 0.611 | Rec. 0.575 | F1 0.583
[[1448  472   48  267   59]
 [ 170 1798   95  209   27]
 [  18  238  264   37   76]
 [ 146  703   43 1243  134]
 [  16   82  109  136  348]]
EVAL:   Pre. 0.604 | Rec. 0.576 | F1 0.583 | BEST F1: 0.337 0
[[3199 1040  106  602  145]
 [ 380 3564  177  495   73]
 [  59  539  489   64  167]
 [ 386 1851  115 2153  197]
 [  50  230  328  293  656]]
TEST:   Pre. 0.562 | Rec. 0.528 | F1 0.534

Epoch:    2 2022-10-21 10:40:27.180337
[[14571  1956   287  1284   340]
 [ 1127 12901   730  1342   159]
 [  107  1331  2691   115   500]
 [ 1473  4206   229  9751   661]
 [  118   399   788   974  3044]]
TRAIN:  Pre. 0.680 | Rec. 0.664 | F1 0.668
[[1676  324   55  187   52]
 [ 256 1698  107  218   20]
 [  32  164  331   33   73]
 [ 261  510   30 1354  114]
 [  31   45   99  130  386]]
EVAL:   Pre. 0.639 | Rec. 0.629 | F1 0.632 | BEST F1: 0.583 1
[[3580  764  108  496  144]
 [ 588 3287  190  562   62]
 [  78  389  615   61  175]
 [ 660 1372   96 2401  173]
 [  90  109  333  279  746]]
TEST:   Pre. 0.587 | Rec. 0.572 | F1 0.576

Epoch:    3 2022-10-21 10:42:00.819856
[[13967  2142   359  1596   374]
 [  469 13806   891   995    98]
 [   57   900  3362    49   376]
 [  581  3167   218 11578   776]
 [   57   175   692   754  3645]]
TRAIN:  Pre. 0.736 | Rec. 0.742 | F1 0.735
[[1535  389   80  231   59]
 [ 145 1734  113  288   19]
 [  26  111  382   28   86]
 [ 137  550   50 1419  113]
 [  22   33  119   95  422]]
EVAL:   Pre. 0.649 | Rec. 0.653 | F1 0.647 | BEST F1: 0.632 2
[[3244  934  150  611  153]
 [ 340 3429  232  625   63]
 [  55  264  770   48  181]
 [ 398 1365  115 2646  178]
 [  69   83  365  194  846]]
TEST:   Pre. 0.613 | Rec. 0.612 | F1 0.606

Epoch:    4 2022-10-21 10:43:33.433788
[[14470  1276   267  1961   464]
 [  454 13108  1011  1538   148]
 [   45   536  3565    62   536]
 [  444   899    76 13863  1038]
 [   39    45   239   604  4396]]
TRAIN:  Pre. 0.778 | Rec. 0.804 | F1 0.787
[[1546  266   73  317   92]
 [ 163 1444  112  535   45]
 [  25   63  374   31  140]
 [ 123  301   29 1654  162]
 [  17    9   76   76  513]]
EVAL:   Pre. 0.651 | Rec. 0.673 | F1 0.656 | BEST F1: 0.647 3
[[3275  566  114  917  220]
 [ 360 2735  223 1261  110]
 [  57  159  711   60  331]
 [ 405  799   91 3167  240]
 [  68   27  271  161 1030]]
TEST:   Pre. 0.606 | Rec. 0.620 | F1 0.609

Epoch:    5 2022-10-21 10:45:18.140268
[[14963  1220   205  1734   316]
 [  398 14094   730   956    81]
 [   35   726  3570    45   368]
 [  390   562    35 14570   763]
 [   31    34   155   867  4236]]
TRAIN:  Pre. 0.818 | Rec. 0.824 | F1 0.819
[[1562  267   65  333   67]
 [ 189 1417   87  576   30]
 [  29   82  335   43  144]
 [ 134  341   27 1658  109]
 [  27   20   76  103  465]]
EVAL:   Pre. 0.644 | Rec. 0.646 | F1 0.642 | BEST F1: 0.656 4

Epoch:    6 2022-10-21 10:46:24.168221
[[15452  1064   189  1456   277]
 [  362 14579   779   505    34]
 [   40   648  3823    25   208]
 [  384   334    16 14771   815]
 [   28    10    90   743  4452]]
TRAIN:  Pre. 0.844 | Rec. 0.856 | F1 0.849
[[1597  230   56  331   80]
 [ 201 1462   86  519   31]
 [  28   81  352   33  139]
 [ 162  335   35 1630  107]
 [  29   14   78   93  477]]
EVAL:   Pre. 0.652 | Rec. 0.659 | F1 0.653 | BEST F1: 0.656 4

Epoch:    7 2022-10-21 10:47:27.064046
[[15755  1170   208  1071   234]
 [  248 15081   785   133    12]
 [   18   617  4032     5    72]
 [  353   488    30 14553   896]
 [   25    20   156   543  4579]]
TRAIN:  Pre. 0.857 | Rec. 0.877 | F1 0.865
[[1596  288   87  256   67]
 [ 203 1684  111  290   11]
 [  32   81  424   16   80]
 [ 151  476   40 1488  114]
 [  31   20  129   57  454]]
EVAL:   Pre. 0.664 | Rec. 0.682 | F1 0.670 | BEST F1: 0.656 4
[[3432  728  147  622  163]
 [ 428 3260  202  743   56]
 [  68  185  839   37  189]
 [ 464 1349  108 2630  151]
 [  86   59  402  145  865]]
TEST:   Pre. 0.616 | Rec. 0.624 | F1 0.616

Epoch:    8 2022-10-21 10:49:07.391200
[[15866   925   169  1250   228]
 [  213 14971   802   258    15]
 [   19   532  4074     9   110]
 [  220   130     7 15084   879]
 [   13    12    41   533  4724]]
TRAIN:  Pre. 0.870 | Rec. 0.890 | F1 0.878
[[1564  207   63  362   98]
 [ 200 1479   91  499   30]
 [  27   65  373   28  140]
 [ 145  341   30 1633  120]
 [  34    7   88   72  490]]
EVAL:   Pre. 0.653 | Rec. 0.669 | F1 0.657 | BEST F1: 0.670 7

Epoch:    9 2022-10-21 10:50:13.148796
[[16479   833   134   841   151]
 [  197 15115   705   229    13]
 [   15   605  4029    12    83]
 [  286    64     3 15219   748]
 [   21     7    20   643  4632]]
TRAIN:  Pre. 0.885 | Rec. 0.895 | F1 0.889
[[1642  228   68  289   67]
 [ 213 1534   83  447   22]
 [  33   74  372   26  128]
 [ 159  359   26 1621  104]
 [  30   16   92   87  466]]
EVAL:   Pre. 0.663 | Rec. 0.672 | F1 0.666 | BEST F1: 0.670 7

Epoch:   10 2022-10-21 10:51:18.115963
[[16535   657   135   921   190]
 [  203 14944   853   246    13]
 [   15   406  4217     7    99]
 [  194    37     0 15198   891]
 [    5     4    22   464  4828]]
TRAIN:  Pre. 0.884 | Rec. 0.909 | F1 0.895
[[1572  203   70  350   99]
 [ 211 1362  100  595   31]
 [  31   48  377   27  150]
 [ 152  259   22 1702  134]
 [  25    7   64   67  528]]
EVAL:   Pre. 0.658 | Rec. 0.677 | F1 0.661 | BEST F1: 0.670 7

Epoch:   11 2022-10-21 10:52:26.562121
[[16461   796   145   883   153]
 [  138 15221   788   104     8]
 [   11   431  4259     2    41]
 [  119    55     1 15261   884]
 [    5     3    30   424  4861]]
TRAIN:  Pre. 0.891 | Rec. 0.915 | F1 0.901
[[1550  244   80  331   89]
 [ 170 1513  105  491   20]
 [  25   54  393   26  135]
 [ 123  420   37 1573  116]
 [  22   12  114   52  491]]
EVAL:   Pre. 0.649 | Rec. 0.672 | F1 0.657 | BEST F1: 0.670 7

Epoch:   12 2022-10-21 10:53:38.083147
[[17128   503    65   627   115]
 [  185 15262   697   109     6]
 [   19   462  4213     3    47]
 [  168    44     3 15372   733]
 [    7     3    14   496  4803]]
TRAIN:  Pre. 0.906 | Rec. 0.920 | F1 0.912
[[1648  207   56  304   79]
 [ 271 1330   80  590   28]
 [  45   57  349   30  152]
 [ 181  241   15 1715  117]
 [  35   11   53   82  510]]
EVAL:   Pre. 0.663 | Rec. 0.668 | F1 0.660 | BEST F1: 0.670 7

Epoch:   13 2022-10-21 10:54:42.419821
[[17135   480    83   618   122]
 [  166 15119   819   145    10]
 [   11   318  4350     2    63]
 [  129    27     1 15296   867]
 [    6     2    16   340  4959]]
TRAIN:  Pre. 0.902 | Rec. 0.929 | F1 0.914
[[1620  191   67  320   96]
 [ 236 1329  100  602   32]
 [  34   40  361   29  169]
 [ 165  261   24 1680  139]
 [  34    7   71   48  531]]
EVAL:   Pre. 0.652 | Rec. 0.673 | F1 0.656 | BEST F1: 0.670 7

Epoch:   14 2022-10-21 10:55:49.050424
[[17355   382    71   520   110]
 [  195 15267   728    62     7]
 [   22   345  4344     2    31]
 [  168    43     3 15231   875]
 [    9     0    16   308  4990]]
TRAIN:  Pre. 0.909 | Rec. 0.933 | F1 0.920
[[1668  206   61  271   88]
 [ 281 1415   94  479   30]
 [  36   50  384   22  141]
 [ 185  323   35 1602  124]
 [  42    6   76   41  526]]
EVAL:   Pre. 0.659 | Rec. 0.683 | F1 0.668 | BEST F1: 0.670 7

Epoch:   15 2022-10-21 10:56:53.298771
[[17337   464    67   466   104]
 [  128 15258   762   107     4]
 [   10   295  4399     2    38]
 [  139    25     1 15324   831]
 [    6     0    30   296  4991]]
TRAIN:  Pre. 0.911 | Rec. 0.937 | F1 0.923
[[1623  241   75  270   85]
 [ 265 1526  110  385   13]
 [  39   45  414   21  114]
 [ 169  339   40 1605  116]
 [  32   13   97   46  503]]
EVAL:   Pre. 0.665 | Rec. 0.692 | F1 0.676 | BEST F1: 0.670 7
[[3461  626  140  677  188]
 [ 468 3017  204  947   53]
 [  83  122  820   32  261]
 [ 461  968   81 3027  165]
 [  94   33  306  112 1012]]
TEST:   Pre. 0.631 | Rec. 0.648 | F1 0.638

Epoch:   16 2022-10-21 10:58:29.036982
[[17527   417    53   357    84]
 [  136 15452   603    65     3]
 [   13   382  4320     3    26]
 [  169    24     0 15506   621]
 [    6     1    11   442  4863]]
TRAIN:  Pre. 0.923 | Rec. 0.935 | F1 0.929
[[1689  217   61  256   71]
 [ 283 1504   91  407   14]
 [  43   57  397   29  107]
 [ 206  334   27 1601  101]
 [  48   14   95   66  468]]
EVAL:   Pre. 0.667 | Rec. 0.680 | F1 0.673 | BEST F1: 0.676 15

Epoch:   17 2022-10-21 10:59:33.546002
[[17446   474    53   386    79]
 [   92 15608   510    47     2]
 [    6   457  4260     0    21]
 [  134    38     1 15549   598]
 [    6     2    26   396  4893]]
TRAIN:  Pre. 0.926 | Rec. 0.935 | F1 0.930
[[1638  244   66  270   76]
 [ 256 1572   85  377    9]
 [  41   79  384   25  104]
 [ 165  428   30 1554   92]
 [  36   25  113   58  459]]
EVAL:   Pre. 0.661 | Rec. 0.671 | F1 0.665 | BEST F1: 0.676 15

Epoch:   18 2022-10-21 11:00:36.565698
[[17625   304    55   374    80]
 [  118 15375   680    84     2]
 [    8   245  4462     2    27]
 [  104    18     0 15466   732]
 [    1     0    16   263  5043]]
TRAIN:  Pre. 0.924 | Rec. 0.947 | F1 0.935
[[1646  216   72  272   88]
 [ 263 1419   95  498   24]
 [  36   49  387   20  141]
 [ 153  342   34 1618  122]
 [  32   13  102   43  501]]
EVAL:   Pre. 0.652 | Rec. 0.677 | F1 0.662 | BEST F1: 0.676 15

Epoch:   19 2022-10-21 11:01:39.475455
[[17667   368    44   304    55]
 [   81 15539   603    33     3]
 [    7   262  4458     0    17]
 [  126    21     0 15512   661]
 [    5     1    12   264  5041]]
TRAIN:  Pre. 0.931 | Rec. 0.950 | F1 0.940
[[1669  230   69  250   76]
 [ 255 1527  100  405   12]
 [  43   51  410   23  106]
 [ 158  352   31 1620  108]
 [  37   14  103   45  492]]
EVAL:   Pre. 0.672 | Rec. 0.693 | F1 0.681 | BEST F1: 0.676 15
[[3499  669  155  618  151]
 [ 480 3049  184  930   46]
 [  96  129  803   28  262]
 [ 499 1002   73 2981  147]
 [ 101   36  307  118  995]]
TEST:   Pre. 0.632 | Rec. 0.644 | F1 0.637

Epoch:   20 2022-10-21 11:03:12.364786
[[17651   347    55   328    57]
 [   86 15525   596    49     3]
 [    6   247  4476     0    15]
 [   84    22     0 15548   666]
 [    1     0    14   243  5065]]
TRAIN:  Pre. 0.931 | Rec. 0.952 | F1 0.941
[[1614  239   74  275   92]
 [ 222 1459   92  505   21]
 [  29   45  390   25  144]
 [ 136  361   32 1633  107]
 [  25   11  109   47  499]]
EVAL:   Pre. 0.656 | Rec. 0.679 | F1 0.665 | BEST F1: 0.681 19

Epoch:   21 2022-10-21 11:04:14.325176
[[17805   241    33   292    67]
 [  109 15409   628   108     5]
 [    8   201  4495     2    38]
 [   93     2     0 15542   683]
 [    1     0     4   205  5113]]
TRAIN:  Pre. 0.932 | Rec. 0.955 | F1 0.942
[[1651  201   70  280   92]
 [ 298 1282   82  602   35]
 [  41   36  350   26  180]
 [ 163  254   22 1703  127]
 [  34    6   71   42  538]]
EVAL:   Pre. 0.652 | Rec. 0.672 | F1 0.655 | BEST F1: 0.681 19

Epoch:   22 2022-10-21 11:05:16.728497
[[17812   266    47   265    48]
 [   91 15577   562    26     3]
 [    5   213  4507     0    19]
 [   88     9     0 15628   595]
 [    1     0    10   232  5080]]
TRAIN:  Pre. 0.938 | Rec. 0.957 | F1 0.947
[[1655  218   75  259   87]
 [ 294 1449   96  445   15]
 [  42   44  391   27  129]
 [ 172  346   24 1615  112]
 [  35   11  106   48  491]]
EVAL:   Pre. 0.656 | Rec. 0.678 | F1 0.665 | BEST F1: 0.681 19

Epoch:   23 2022-10-21 11:06:19.367607
[[17864   233    36   251    54]
 [   95 15576   549    37     2]
 [    5   202  4515     0    22]
 [   83     5     0 15567   665]
 [    1     0     4   172  5146]]
TRAIN:  Pre. 0.938 | Rec. 0.960 | F1 0.948
[[1635  215   71  281   92]
 [ 253 1451   89  484   22]
 [  42   43  381   26  141]
 [ 161  321   24 1643  120]
 [  31    8   92   43  517]]
EVAL:   Pre. 0.661 | Rec. 0.684 | F1 0.669 | BEST F1: 0.681 19

Epoch:   24 2022-10-21 11:07:21.883371
[[17893   261    37   200    47]
 [   87 15598   556    16     2]
 [    4   183  4547     0    10]
 [  103     7     0 15615   595]
 [    2     0    13   194  5114]]
TRAIN:  Pre. 0.941 | Rec. 0.961 | F1 0.950
[[1655  222   69  259   89]
 [ 286 1492  101  403   17]
 [  45   49  399   19  121]
 [ 170  376   27 1589  107]
 [  32   11  115   43  490]]
EVAL:   Pre. 0.659 | Rec. 0.682 | F1 0.669 | BEST F1: 0.681 19

Epoch:   25 2022-10-21 11:08:24.610754
[[17982   203    32   185    36]
 [  105 15597   535    20     2]
 [    5   156  4571     0    12]
 [  101     3     0 15627   589]
 [    3     0     5   175  5140]]
TRAIN:  Pre. 0.944 | Rec. 0.964 | F1 0.953
[[1703  217   68  226   80]
 [ 319 1506   92  366   16]
 [  54   42  398   25  114]
 [ 188  407   32 1536  106]
 [  41   13  116   39  482]]
EVAL:   Pre. 0.659 | Rec. 0.680 | F1 0.669 | BEST F1: 0.681 19

Epoch:   26 2022-10-21 11:09:27.726098
[[17913   243    39   207    36]
 [   78 15658   500    21     2]
 [    6   168  4558     0    12]
 [   68     7     0 15659   586]
 [    1     0    15   158  5149]]
TRAIN:  Pre. 0.945 | Rec. 0.964 | F1 0.954
[[1648  239   70  255   82]
 [ 234 1554   97  401   13]
 [  40   48  409   19  117]
 [ 145  390   29 1597  108]
 [  31   14  118   40  488]]
EVAL:   Pre. 0.668 | Rec. 0.690 | F1 0.677 | BEST F1: 0.681 19

Epoch:   27 2022-10-21 11:10:30.298761
[[17982   198    35   188    35]
 [   94 15625   519    19     2]
 [    4   140  4588     0    12]
 [   76     7     0 15575   662]
 [    2     0    14   107  5200]]
TRAIN:  Pre. 0.944 | Rec. 0.967 | F1 0.954
[[1656  242   76  244   76]
 [ 268 1545  106  367   13]
 [  43   45  417   16  112]
 [ 164  421   37 1538  109]
 [  37   11  133   36  474]]
EVAL:   Pre. 0.658 | Rec. 0.683 | F1 0.669 | BEST F1: 0.681 19

Epoch:   28 2022-10-21 11:11:34.732533
[[18021   170    19   191    37]
 [   94 15633   491    39     2]
 [    5   146  4576     0    17]
 [   69     2     0 15694   555]
 [    2     0     3   148  5170]]
TRAIN:  Pre. 0.948 | Rec. 0.967 | F1 0.957
[[1674  210   64  263   83]
 [ 293 1387   84  513   22]
 [  46   45  365   28  149]
 [ 173  287   19 1679  111]
 [  39    7   81   46  518]]
EVAL:   Pre. 0.663 | Rec. 0.680 | F1 0.668 | BEST F1: 0.681 19

Epoch:   29 2022-10-21 11:12:37.797983
[[18081   161    25   148    23]
 [  107 15656   485     9     2]
 [    5   135  4595     0     9]
 [   87     5     0 15668   560]
 [    2     0     6   125  5190]]
TRAIN:  Pre. 0.950 | Rec. 0.969 | F1 0.959
[[1720  206   67  222   79]
 [ 310 1473   89  406   21]
 [  48   46  395   19  125]
 [ 193  345   25 1594  112]
 [  39   12   99   40  501]]
EVAL:   Pre. 0.667 | Rec. 0.688 | F1 0.676 | BEST F1: 0.681 19

Epoch:   30 2022-10-21 11:13:40.951092
[[18062   167    22   163    24]
 [  103 15599   533    22     2]
 [    4    93  4637     0    10]
 [   70     5     0 15667   578]
 [    2     0     9   104  5208]]
TRAIN:  Pre. 0.948 | Rec. 0.971 | F1 0.959
[[1697  219   68  232   78]
 [ 282 1505  102  393   17]
 [  48   41  413   20  111]
 [ 185  404   32 1536  112]
 [  38   13  119   34  487]]
EVAL:   Pre. 0.661 | Rec. 0.686 | F1 0.672 | BEST F1: 0.681 19

Epoch:   31 2022-10-21 11:14:43.938846
[[18039   163    22   184    30]
 [   88 15640   501    28     2]
 [    3   110  4620     0    11]
 [   53     8     0 15693   566]
 [    0     0    13    99  5211]]
TRAIN:  Pre. 0.949 | Rec. 0.971 | F1 0.959
[[1635  224   75  276   84]
 [ 256 1503   96  424   20]
 [  36   42  412   21  122]
 [ 160  383   30 1584  112]
 [  30   14  112   37  498]]
EVAL:   Pre. 0.661 | Rec. 0.687 | F1 0.672 | BEST F1: 0.681 19

Epoch:   32 2022-10-21 11:15:46.578216
[[18153   110    19   130    26]
 [  132 15588   503    34     2]
 [    7    94  4632     0    11]
 [   93     4     0 15713   510]
 [    2     0     5   112  5204]]
TRAIN:  Pre. 0.952 | Rec. 0.972 | F1 0.961
[[1740  189   62  223   80]
 [ 358 1351   90  476   24]
 [  56   35  373   28  141]
 [ 211  276   23 1649  110]
 [  41    9   79   44  518]]
EVAL:   Pre. 0.664 | Rec. 0.682 | F1 0.670 | BEST F1: 0.681 19

Epoch:   33 2022-10-21 11:16:51.393745
[[18074   128    17   185    34]
 [   83 15675   462    37     2]
 [    4   104  4623     0    13]
 [   49     1     0 15783   487]
 [    0     0     2   119  5202]]
TRAIN:  Pre. 0.954 | Rec. 0.973 | F1 0.963
[[1654  212   66  274   88]
 [ 289 1403   85  501   21]
 [  45   39  373   26  150]
 [ 168  293   23 1677  108]
 [  31   10   84   47  519]]
EVAL:   Pre. 0.663 | Rec. 0.682 | F1 0.669 | BEST F1: 0.681 19

Epoch:   34 2022-10-21 11:17:55.367213
[[18075   142    20   170    31]
 [   76 15690   480    11     2]
 [    4    88  4643     0     9]
 [   45     2     0 15753   520]
 [    0     0     4    98  5221]]
TRAIN:  Pre. 0.953 | Rec. 0.974 | F1 0.963
[[1655  218   71  266   84]
 [ 280 1499   92  407   21]
 [  47   40  400   20  126]
 [ 167  374   32 1591  105]
 [  33   12  110   39  497]]
EVAL:   Pre. 0.661 | Rec. 0.685 | F1 0.672 | BEST F1: 0.681 19

Epoch:   35 2022-10-21 11:18:59.846759
[[18033   191    26   162    26]
 [   56 15742   442    17     2]
 [    3   101  4630     0    10]
 [   46     4     0 15784   486]
 [    0     0     8   108  5207]]
TRAIN:  Pre. 0.955 | Rec. 0.974 | F1 0.964
[[1632  240   74  263   85]
 [ 235 1576   96  378   14]
 [  39   48  419   19  108]
 [ 151  431   31 1555  101]
 [  30   14  120   41  486]]
EVAL:   Pre. 0.666 | Rec. 0.690 | F1 0.676 | BEST F1: 0.681 19

Epoch:   36 2022-10-21 11:20:03.540627
[[18137   129    22   129    21]
 [   84 15678   477    18     2]
 [    4    84  4644     0    12]
 [   58     3     0 15740   519]
 [    0     0     4    89  5230]]
TRAIN:  Pre. 0.954 | Rec. 0.975 | F1 0.964
[[1694  207   69  245   79]
 [ 294 1456   95  432   22]
 [  47   40  393   22  131]
 [ 169  344   27 1618  111]
 [  34   11  106   37  503]]
EVAL:   Pre. 0.663 | Rec. 0.687 | F1 0.673 | BEST F1: 0.681 19

Epoch:   37 2022-10-21 11:21:05.153415
[[18121   132    23   138    24]
 [   79 15727   435    16     2]
 [    4    96  4634     0    10]
 [   50     3     0 15775   492]
 [    0     0     4    96  5223]]
TRAIN:  Pre. 0.956 | Rec. 0.975 | F1 0.965
[[1667  217   68  260   82]
 [ 284 1465   87  442   21]
 [  45   39  389   25  135]
 [ 167  339   26 1629  108]
 [  32   12  104   43  500]]
EVAL:   Pre. 0.663 | Rec. 0.684 | F1 0.671 | BEST F1: 0.681 19

Epoch:   38 2022-10-21 11:22:07.491492
[[18098   149    23   143    25]
 [   65 15729   452    11     2]
 [    4    81  4650     0     9]
 [   47     3     0 15760   510]
 [    0     0     4    89  5230]]
TRAIN:  Pre. 0.955 | Rec. 0.975 | F1 0.965
[[1656  221   70  262   85]
 [ 265 1502   96  416   20]
 [  43   42  404   22  122]
 [ 162  370   28 1599  110]
 [  31   12  111   38  499]]
EVAL:   Pre. 0.664 | Rec. 0.688 | F1 0.674 | BEST F1: 0.681 19

Epoch:   39 2022-10-21 11:23:09.910351
[[18097   149    23   144    25]
 [   65 15737   444    11     2]
 [    4    84  4647     0     9]
 [   47     3     0 15769   501]
 [    0     0     4    91  5228]]
TRAIN:  Pre. 0.956 | Rec. 0.975 | F1 0.965
[[1655  219   69  267   84]
 [ 266 1495   91  426   21]
 [  43   43  398   22  127]
 [ 164  363   27 1607  108]
 [  31   12  109   40  499]]
EVAL:   Pre. 0.663 | Rec. 0.686 | F1 0.673 | BEST F1: 0.681 19

[Info] Building character-level LSTM

Inference:

[[17667   368    44   304    55]
 [   81 15539   603    33     3]
 [    7   262  4458     0    17]
 [  126    21     0 15512   661]
 [    5     1    12   264  5041]]
TRAIN:  Pre. 0.931 | Rec. 0.950 | F1 0.940
[[1669  230   69  250   76]
 [ 255 1527  100  405   12]
 [  43   51  410   23  106]
 [ 158  352   31 1620  108]
 [  37   14  103   45  492]]
EVAL:   Pre. 0.672 | Rec. 0.693 | F1 0.681
[[3499  669  155  618  151]
 [ 480 3049  184  930   46]
 [  96  129  803   28  262]
 [ 499 1002   73 2981  147]
 [ 101   36  307  118  995]]
TEST:   Pre. 0.632 | Rec. 0.644 | F1 0.637

Process finished with exit code 0
