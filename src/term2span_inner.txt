ssh://fuyj@115.24.15.21:22/home/fuyj/workspace/venv/torch/bin/python3 -u /home/fuyj/.pycharm_helpers/pydev/pydevd.py --multiproc --qt-support=auto --client 0.0.0.0 --port 41959 --file /home/fuyj/workspace/experiment/ABAM-main/src/run_AURC_token_term2span.py
pydev debugger: process 2504 is connecting

Connected to pydev debugger (build 193.7288.30)
device cuda:0
../models_final/aurc_in_token.pt
../models_final/aurc_in_config.json
../models_final/aurc_in_predictions_dev.json
../models_final/aurc_in_predictions_test.json
../data/../data/data_dict_bert_pieces2word.json
数据集大小
4396
8 ['abortion', 'cloning', 'death penalty', 'gun control', 'marijuana legalization', 'minimum wage', 'nuclear energy', 'school uniforms']
{'abortion': 415, 'death penalty': 588, 'gun control': 480, 'marijuana legalization': 626, 'minimum wage': 624, 'nuclear energy': 615, 'school uniforms': 705, 'cloning': 343}
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
/home/fuyj/workspace/venv/torch/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,
0
/home/fuyj/workspace/experiment/ABAM-main/src/run_AURC_token_term2span.py:342: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)
  all_pieces2word = torch.tensor([f.pieces2word for f in train_features])
2268 71
307 307
636 636
Some weights of the model checkpoint at ../model_base/ were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2800
##### DOMAIN: inner , use CRF: True , learning-rate: 1e-05 , DROPOUT: 0.1

Epoch:    0 2022-09-03 22:23:19.357005
/home/fuyj/workspace/venv/torch/lib/python3.6/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
[[11502  4127     0  2809     0]
 [ 1802 11254     0  3203     0]
 [  122  2965     0  1657     0]
 [ 1817  6596     0  7907     0]
 [   97  1496     0  3729     1]]
TRAIN:  Pre. 0.517 | Rec. 0.360 | F1 0.330
[[1417  556    0  321    0]
 [ 287 1675    0  337    0]
 [  17  392    0  224    0]
 [ 275  704    0 1290    0]
 [  16  143    0  532    0]]
EVAL:   Pre. 0.333 | Rec. 0.383 | F1 0.352 | BEST F1: 0.000 None
[[3115 1247    0  730    0]
 [ 623 3325    0  741    0]
 [  49  823    0  446    0]
 [ 685 1781    0 2236    0]
 [  50  431    0 1076    0]]
TEST:   Pre. 0.311 | Rec. 0.359 | F1 0.328

Epoch:    1 2022-09-03 22:24:54.272955
[[13014  2745    14  2483   182]
 [ 1367 11498    47  3161   186]
 [   86  2594   260  1129   675]
 [ 1431  4288    15 10284   302]
 [   86   699    48  2815  1675]]
TRAIN:  Pre. 0.618 | Rec. 0.483 | F1 0.486
[[1524  423    7  308   32]
 [ 260 1660   10  340   29]
 [  23  324   30  168   88]
 [ 250  489    1 1472   57]
 [  21   91    3  336  240]]
EVAL:   Pre. 0.595 | Rec. 0.486 | F1 0.487 | BEST F1: 0.352 0
[[3326  926    6  767   67]
 [ 574 3225    6  839   45]
 [  49  705   61  344  159]
 [ 607 1255    2 2745   93]
 [  47  219    8  868  415]]
TEST:   Pre. 0.599 | Rec. 0.448 | F1 0.450

Epoch:    2 2022-09-03 22:26:33.166760
[[13614  1569   127  2673   455]
 [ 1187 10859   464  3385   364]
 [   74  1436  1668   452  1114]
 [  999  2038    62 12326   895]
 [   62   233   192  1386  3450]]
TRAIN:  Pre. 0.670 | Rec. 0.632 | F1 0.638
[[1546  279   25  368   76]
 [ 262 1447   58  481   51]
 [  25  168  195   77  168]
 [ 197  284    8 1631  149]
 [  15   36   28  190  422]]
EVAL:   Pre. 0.622 | Rec. 0.588 | F1 0.592 | BEST F1: 0.487 1
[[3379  610   47  851  205]
 [ 573 2710  114 1179  113]
 [  63  415  362  159  319]
 [ 522  809   29 3101  241]
 [  54   95  104  423  881]]
TEST:   Pre. 0.583 | Rec. 0.548 | F1 0.555

Epoch:    3 2022-09-03 22:28:08.601390
[[13498  2139   240  2172   389]
 [  583 13292   874  1365   145]
 [   50  1232  2820   116   526]
 [  574  2575   179 12029   963]
 [   45   201   442   907  3728]]
TRAIN:  Pre. 0.718 | Rec. 0.716 | F1 0.714
[[1473  394   52  310   65]
 [ 172 1674  112  311   30]
 [  22  145  330   42   94]
 [ 137  475   30 1477  150]
 [  12   37   96  116  430]]
EVAL:   Pre. 0.634 | Rec. 0.633 | F1 0.630 | BEST F1: 0.592 2
[[3168  905  101  727  191]
 [ 379 3317  218  702   73]
 [  57  388  611   62  200]
 [ 409 1138   66 2844  245]
 [  57   97  226  254  923]]
TEST:   Pre. 0.606 | Rec. 0.598 | F1 0.599

Epoch:    4 2022-09-03 22:29:45.833769
[[14341  1558   184  2014   341]
 [  627 13578   736  1218   100]
 [   54  1267  2864   106   453]
 [  591  1337    76 13430   886]
 [   50   106   226  1036  3905]]
TRAIN:  Pre. 0.764 | Rec. 0.755 | F1 0.757
[[1554  292   44  343   61]
 [ 210 1616   90  358   25]
 [  28  141  317   46  101]
 [ 168  357   22 1591  131]
 [  17   31   75  139  429]]
EVAL:   Pre. 0.649 | Rec. 0.641 | F1 0.643 | BEST F1: 0.630 3
[[3307  731   80  796  178]
 [ 471 3084  174  890   70]
 [  75  364  565   84  230]
 [ 462  942   53 3031  214]
 [  71   86  215  279  906]]
TEST:   Pre. 0.606 | Rec. 0.592 | F1 0.597

Epoch:    5 2022-09-03 22:31:23.239368
[[16017  1030   156   990   245]
 [  992 13882   739   594    52]
 [   80  1185  3179    59   241]
 [ 1241   846    61 13390   782]
 [   88    81   194  1026  3934]]
TRAIN:  Pre. 0.800 | Rec. 0.790 | F1 0.795
[[1790  198   49  207   50]
 [ 408 1460   87  321   23]
 [  50  127  329   36   91]
 [ 299  418   37 1423   92]
 [  41   36  102  124  388]]
EVAL:   Pre. 0.633 | Rec. 0.625 | F1 0.628 | BEST F1: 0.643 4

Epoch:    6 2022-09-03 22:32:33.401609
[[14330  1485   264  1952   407]
 [  281 14047  1212   641    78]
 [   21   556  3864    34   269]
 [  295   351    40 14482  1152]
 [   21    17   104   637  4544]]
TRAIN:  Pre. 0.807 | Rec. 0.839 | F1 0.819
[[1452  269   59  416   98]
 [ 137 1488  126  503   45]
 [  22   74  367   31  139]
 [ 108  354   40 1603  164]
 [  11   10   93   89  488]]
EVAL:   Pre. 0.636 | Rec. 0.655 | F1 0.639 | BEST F1: 0.643 4

Epoch:    7 2022-09-03 22:33:43.914558
[[15479  1311   196  1203   249]
 [  300 14972   800   169    18]
 [   22   945  3683    10    84]
 [  396   447    34 14509   934]
 [   29    32   142   731  4389]]
TRAIN:  Pre. 0.841 | Rec. 0.850 | F1 0.844
[[1600  288   58  284   64]
 [ 210 1633   94  339   23]
 [  30  113  366   31   93]
 [ 159  452   40 1501  117]
 [  19   25  136   94  417]]
EVAL:   Pre. 0.644 | Rec. 0.650 | F1 0.646 | BEST F1: 0.643 4
[[3328  796  125  663  180]
 [ 423 3280  212  730   44]
 [  72  272  748   50  176]
 [ 470 1092   90 2873  177]
 [  78   64  321  180  914]]
TEST:   Pre. 0.622 | Rec. 0.624 | F1 0.621

Epoch:    8 2022-09-03 22:35:21.674305
[[16289   704   121  1111   213]
 [  477 14549   803   405    25]
 [   40   752  3766    26   160]
 [  416   147     7 14886   864]
 [   47    10    45   764  4457]]
TRAIN:  Pre. 0.857 | Rec. 0.864 | F1 0.860
[[1697  180   38  307   72]
 [ 301 1343   80  536   39]
 [  41   82  307   47  156]
 [ 204  269   27 1643  126]
 [  37    7   72  110  465]]
EVAL:   Pre. 0.642 | Rec. 0.641 | F1 0.637 | BEST F1: 0.646 7

Epoch:    9 2022-09-03 22:36:33.375795
[[16096   849   149  1111   233]
 [  287 14831   930   192    19]
 [   24   569  4059    10    82]
 [  266   146    12 14892  1004]
 [   21     6    47   531  4718]]
TRAIN:  Pre. 0.864 | Rec. 0.888 | F1 0.874
[[1577  240   62  327   88]
 [ 249 1439  101  471   39]
 [  35   70  359   29  140]
 [ 156  422   45 1516  130]
 [  18   19  133   66  455]]
EVAL:   Pre. 0.622 | Rec. 0.641 | F1 0.629 | BEST F1: 0.646 7

Epoch:   10 2022-09-03 22:37:44.509313
[[16987   571    89   656   135]
 [  392 14936   765   158     8]
 [   30   637  4008     8    61]
 [  408   114     8 14982   808]
 [   30     6    38   652  4597]]
TRAIN:  Pre. 0.883 | Rec. 0.893 | F1 0.888
[[1775  184   45  225   65]
 [ 400 1403   86  382   28]
 [  57   76  352   28  120]
 [ 242  400   35 1485  107]
 [  40   20  115   92  424]]
EVAL:   Pre. 0.635 | Rec. 0.642 | F1 0.638 | BEST F1: 0.646 7

Epoch:   11 2022-09-03 22:38:54.743845
[[16817   728   109   652   132]
 [  221 15101   856    69    12]
 [   16   522  4177     0    29]
 [  279   140    14 14998   889]
 [   20     3    41   505  4754]]
TRAIN:  Pre. 0.886 | Rec. 0.907 | F1 0.895
[[1687  229   62  249   67]
 [ 323 1514  101  335   26]
 [  45   67  392   25  104]
 [ 203  428   42 1479  117]
 [  29   23  130   72  437]]
EVAL:   Pre. 0.643 | Rec. 0.659 | F1 0.650 | BEST F1: 0.646 7
[[3550  613  129  618  182]
 [ 570 3014  216  833   56]
 [  94  182  766   47  229]
 [ 581  846   62 3009  204]
 [ 121   40  257  125 1014]]
TEST:   Pre. 0.630 | Rec. 0.642 | F1 0.636

Epoch:   12 2022-09-03 22:40:32.153775
[[16742   662   104   789   141]
 [  183 15059   893   115     9]
 [   15   413  4273     4    39]
 [  169    76     7 15195   873]
 [   18     1    28   461  4815]]
TRAIN:  Pre. 0.890 | Rec. 0.914 | F1 0.901
[[1626  209   58  320   81]
 [ 241 1446   98  481   33]
 [  34   59  368   30  142]
 [ 166  361   28 1585  129]
 [  23   15  103   77  473]]
EVAL:   Pre. 0.644 | Rec. 0.660 | F1 0.650 | BEST F1: 0.650 11

Epoch:   13 2022-09-03 22:41:41.536304
[[17169   514    83   556   116]
 [  189 15027   965    75     3]
 [   13   313  4387     3    28]
 [  176    81     7 15119   937]
 [   15     1    19   353  4935]]
TRAIN:  Pre. 0.897 | Rec. 0.927 | F1 0.910
[[1696  215   60  247   76]
 [ 297 1439  111  421   31]
 [  43   50  384   24  132]
 [ 184  433   48 1477  127]
 [  27   14  127   62  461]]
EVAL:   Pre. 0.634 | Rec. 0.658 | F1 0.644 | BEST F1: 0.650 11

Epoch:   14 2022-09-03 22:42:51.740409
[[17240   499    76   522   101]
 [  183 15265   746    63     2]
 [   14   437  4267     3    23]
 [  170    51     2 15327   770]
 [    4     1    25   416  4877]]
TRAIN:  Pre. 0.907 | Rec. 0.926 | F1 0.916
[[1662  212   58  278   84]
 [ 288 1446   86  449   30]
 [  38   64  362   30  139]
 [ 184  348   27 1593  117]
 [  26   14   97   71  483]]
EVAL:   Pre. 0.650 | Rec. 0.665 | F1 0.656 | BEST F1: 0.650 11
[[3553  519  124  688  208]
 [ 574 2961  198  915   41]
 [  92  165  767   44  250]
 [ 527  759   44 3178  194]
 [  99   30  225  132 1071]]
TEST:   Pre. 0.643 | Rec. 0.655 | F1 0.648

Epoch:   15 2022-09-03 22:44:29.106709
[[17456   406    56   443    77]
 [  179 15325   630   120     5]
 [   21   486  4207     3    27]
 [  184    26     0 15453   657]
 [   10     1    16   481  4815]]
TRAIN:  Pre. 0.916 | Rec. 0.926 | F1 0.920
[[1734  194   40  264   62]
 [ 338 1457   76  406   22]
 [  51   73  360   26  123]
 [ 207  369   22 1574   97]
 [  40   18  105   88  440]]
EVAL:   Pre. 0.656 | Rec. 0.658 | F1 0.656 | BEST F1: 0.656 14
[[3708  464   90  660  170]
 [ 676 2842  158  969   44]
 [ 131  169  727   54  237]
 [ 627  749   47 3126  153]
 [ 132   35  229  160 1001]]
TEST:   Pre. 0.641 | Rec. 0.639 | F1 0.639

Epoch:   16 2022-09-03 22:46:06.664031
[[17153   483    70   620   112]
 [  120 15160   851   122     6]
 [    7   278  4421     2    36]
 [   93    15     0 15368   844]
 [    1     1     4   276  5041]]
TRAIN:  Pre. 0.908 | Rec. 0.937 | F1 0.921
[[1556  218   60  359  101]
 [ 202 1404   99  555   39]
 [  29   49  369   25  161]
 [ 130  289   23 1682  145]
 [  18    8   78   57  530]]
EVAL:   Pre. 0.655 | Rec. 0.676 | F1 0.659 | BEST F1: 0.656 15
[[3309  520  105  879  279]
 [ 442 2701  198 1264   84]
 [  80  111  737   43  347]
 [ 400  613   48 3426  215]
 [  74   17  198  113 1155]]
TEST:   Pre. 0.635 | Rec. 0.651 | F1 0.637

Epoch:   17 2022-09-03 22:47:47.779276
[[17801   303    48   231    55]
 [  206 15310   733    10     0]
 [   13   319  4407     1     4]
 [  286    53     9 15218   754]
 [   15     2    17   275  5014]]
TRAIN:  Pre. 0.920 | Rec. 0.942 | F1 0.930
[[1782  216   61  174   61]
 [ 379 1517   92  286   25]
 [  52   64  398   16  103]
 [ 273  425   35 1421  115]
 [  46   19  128   48  450]]
EVAL:   Pre. 0.653 | Rec. 0.669 | F1 0.659 | BEST F1: 0.659 16
[[3775  519  122  517  159]
 [ 682 3027  196  737   47]
 [ 126  140  819   32  201]
 [ 724  914   69 2826  169]
 [ 135   37  280   99 1006]]
TEST:   Pre. 0.641 | Rec. 0.651 | F1 0.645

Epoch:   18 2022-09-03 22:49:27.344910
[[17369   479    59   461    70]
 [   71 15382   785    20     1]
 [    6   249  4483     0     6]
 [   81    61     3 15340   835]
 [    0     0    27   210  5086]]
TRAIN:  Pre. 0.917 | Rec. 0.946 | F1 0.930
[[1573  282   71  288   80]
 [ 194 1597  105  376   27]
 [  31   61  410   17  114]
 [ 148  427   35 1524  135]
 [  23   18  118   42  490]]
EVAL:   Pre. 0.656 | Rec. 0.682 | F1 0.666 | BEST F1: 0.659 17
[[3393  676  139  667  217]
 [ 434 3104  219  879   53]
 [  88  122  835   30  243]
 [ 431  906   65 3107  193]
 [  89   28  281   92 1067]]
TEST:   Pre. 0.640 | Rec. 0.662 | F1 0.649

Epoch:   19 2022-09-03 22:51:04.902821
[[17805   255    42   289    47]
 [  145 15350   692    70     2]
 [   15   274  4441     2    12]
 [  111    29     2 15479   699]
 [    4     1     4   264  5050]]
TRAIN:  Pre. 0.927 | Rec. 0.949 | F1 0.937
[[1744  173   42  254   81]
 [ 347 1424   87  413   28]
 [  52   55  369   21  136]
 [ 228  331   30 1561  119]
 [  40   16   86   63  486]]
EVAL:   Pre. 0.657 | Rec. 0.671 | F1 0.662 | BEST F1: 0.666 18

Epoch:   20 2022-09-03 22:52:14.600609
[[17809   254    44   280    51]
 [  113 15298   810    36     2]
 [   12   182  4539     0    11]
 [  111     7     0 15414   788]
 [    4     0     9   194  5116]]
TRAIN:  Pre. 0.925 | Rec. 0.954 | F1 0.938
[[1701  198   57  258   80]
 [ 276 1462  107  422   32]
 [  43   44  388   21  137]
 [ 189  334   28 1581  137]
 [  38   12   86   52  503]]
EVAL:   Pre. 0.659 | Rec. 0.683 | F1 0.669 | BEST F1: 0.666 18
[[3600  488  117  673  214]
 [ 602 2802  203 1017   65]
 [ 107  112  779   35  285]
 [ 521  690   55 3227  209]
 [ 104   14  215  100 1124]]
TEST:   Pre. 0.642 | Rec. 0.661 | F1 0.650

Epoch:   21 2022-09-03 22:53:51.919891
[[17838   296    41   222    41]
 [   95 15552   612     0     0]
 [    6   270  4468     0     0]
 [  134    40     4 15467   675]
 [    6     1    16   222  5078]]
TRAIN:  Pre. 0.933 | Rec. 0.954 | F1 0.943
[[1715  257   65  195   62]
 [ 263 1638   85  294   19]
 [  43   70  407   14   99]
 [ 202  484   33 1440  110]
 [  35   22  143   56  435]]
EVAL:   Pre. 0.660 | Rec. 0.673 | F1 0.665 | BEST F1: 0.669 20

Epoch:   22 2022-09-03 22:55:01.625599
[[17887   248    38   216    49]
 [   96 15390   748    25     0]
 [    4   162  4569     0     9]
 [   96     1     0 15422   801]
 [    0     0     3   152  5168]]
TRAIN:  Pre. 0.930 | Rec. 0.959 | F1 0.943
[[1697  221   62  237   77]
 [ 268 1555  106  342   28]
 [  37   55  412   15  114]
 [ 193  431   34 1474  137]
 [  34   16  128   36  477]]
EVAL:   Pre. 0.654 | Rec. 0.681 | F1 0.666 | BEST F1: 0.669 20

Epoch:   23 2022-09-03 22:56:11.754227
[[17897   231    33   234    43]
 [   95 15391   737    36     0]
 [    5   146  4575     0    18]
 [   75     1     0 15521   723]
 [    1     0     2   146  5174]]
TRAIN:  Pre. 0.933 | Rec. 0.961 | F1 0.946
[[1686  208   51  267   82]
 [ 280 1466  103  419   31]
 [  43   45  393   18  134]
 [ 199  326   22 1580  142]
 [  33   13   80   48  517]]
EVAL:   Pre. 0.664 | Rec. 0.688 | F1 0.673 | BEST F1: 0.669 20
[[3607  456  118  698  213]
 [ 605 2797  199 1018   70]
 [ 111  115  764   36  292]
 [ 514  727   56 3206  199]
 [ 108   19  216   90 1124]]
TEST:   Pre. 0.640 | Rec. 0.658 | F1 0.647

Epoch:   24 2022-09-03 22:57:49.478891
[[17859   254    35   248    42]
 [   65 15525   641    28     0]
 [    3   163  4564     0    14]
 [   56     2     0 15611   651]
 [    1     0     4   172  5146]]
TRAIN:  Pre. 0.938 | Rec. 0.962 | F1 0.949
[[1608  274   64  275   73]
 [ 216 1590   92  374   27]
 [  34   57  408   17  117]
 [ 161  422   31 1533  122]
 [  25   17  116   53  480]]
EVAL:   Pre. 0.660 | Rec. 0.681 | F1 0.669 | BEST F1: 0.673 23

Epoch:   25 2022-09-03 22:59:00.650301
[[17887   262    33   222    34]
 [   59 15474   693    31     2]
 [    4   136  4589     0    15]
 [   60     2     0 15563   695]
 [    2     0     4   122  5195]]
TRAIN:  Pre. 0.936 | Rec. 0.964 | F1 0.949
[[1625  263   61  269   76]
 [ 201 1607  101  361   29]
 [  36   56  415   14  112]
 [ 172  429   31 1504  133]
 [  30   15  123   40  483]]
EVAL:   Pre. 0.660 | Rec. 0.685 | F1 0.670 | BEST F1: 0.673 23

Epoch:   26 2022-09-03 23:00:12.086612
[[17991   180    27   209    31]
 [   86 15476   644    51     2]
 [    6   125  4596     0    17]
 [   64     1     0 15661   594]
 [    0     0     4   161  5158]]
TRAIN:  Pre. 0.941 | Rec. 0.965 | F1 0.952
[[1695  225   52  252   70]
 [ 266 1500   95  411   27]
 [  42   51  391   19  130]
 [ 201  328   21 1600  119]
 [  32   13   89   55  502]]
EVAL:   Pre. 0.669 | Rec. 0.688 | F1 0.677 | BEST F1: 0.673 23
[[3572  504  120  699  197]
 [ 598 2875  188  974   54]
 [ 108  122  781   41  266]
 [ 503  760   51 3216  172]
 [ 108   24  235  109 1081]]
TEST:   Pre. 0.644 | Rec. 0.657 | F1 0.649

Epoch:   27 2022-09-03 23:01:49.143057
[[17921   233    29   220    35]
 [   53 15563   627    15     1]
 [    5   122  4616     0     1]
 [   41    19     0 15586   674]
 [    0     0     5   105  5213]]
TRAIN:  Pre. 0.941 | Rec. 0.967 | F1 0.953
[[1630  278   61  251   74]
 [ 195 1618  100  364   22]
 [  29   54  416   16  118]
 [ 168  440   32 1499  130]
 [  25   18  127   39  482]]
EVAL:   Pre. 0.662 | Rec. 0.686 | F1 0.671 | BEST F1: 0.677 26

Epoch:   28 2022-09-03 23:02:59.131640
[[18028   167    25   191    27]
 [   85 15575   574    25     0]
 [    6   133  4603     0     2]
 [   53    11     1 15674   581]
 [    0     0     6   141  5176]]
TRAIN:  Pre. 0.946 | Rec. 0.968 | F1 0.956
[[1690  225   55  252   72]
 [ 251 1540   90  393   25]
 [  38   55  397   21  122]
 [ 187  349   25 1589  119]
 [  33   13   96   53  496]]
EVAL:   Pre. 0.671 | Rec. 0.690 | F1 0.679 | BEST F1: 0.677 26
[[3580  539  119  656  198]
 [ 598 2968  190  888   45]
 [ 110  124  808   37  239]
 [ 516  831   55 3132  168]
 [ 103   28  253  103 1070]]
TEST:   Pre. 0.646 | Rec. 0.660 | F1 0.653

Epoch:   29 2022-09-03 23:04:36.959057
[[18000   191    24   195    28]
 [   59 15584   603    13     0]
 [    6   107  4629     0     2]
 [   44     1     0 15663   612]
 [    2     0     3   109  5209]]
TRAIN:  Pre. 0.945 | Rec. 0.970 | F1 0.956
[[1644  238   51  283   78]
 [ 223 1550   94  405   27]
 [  35   54  398   20  126]
 [ 183  335   26 1602  123]
 [  31   13   88   50  509]]
EVAL:   Pre. 0.672 | Rec. 0.692 | F1 0.680 | BEST F1: 0.679 28
[[3488  574  128  700  202]
 [ 522 2981  196  939   51]
 [ 104  120  799   36  259]
 [ 480  828   56 3158  180]
 [ 104   28  246   96 1083]]
TEST:   Pre. 0.642 | Rec. 0.659 | F1 0.650

Epoch:   30 2022-09-03 23:06:14.083498
[[18052   163    18   178    27]
 [   64 15570   623     2     0]
 [    3    92  4647     0     2]
 [   46     5     0 15655   614]
 [    0     0     2    98  5223]]
TRAIN:  Pre. 0.946 | Rec. 0.971 | F1 0.957
[[1669  238   54  254   79]
 [ 240 1526  106  400   27]
 [  37   51  395   21  129]
 [ 189  351   26 1574  129]
 [  31   14   94   47  505]]
EVAL:   Pre. 0.664 | Rec. 0.688 | F1 0.674 | BEST F1: 0.680 29

Epoch:   31 2022-09-03 23:07:23.881034
[[18062   153    16   186    21]
 [   61 15604   580    14     0]
 [    4   100  4637     0     3]
 [   47     1     0 15733   539]
 [    2     0     2   125  5194]]
TRAIN:  Pre. 0.949 | Rec. 0.971 | F1 0.959
[[1658  234   56  274   72]
 [ 219 1561   98  396   25]
 [  37   53  399   23  121]
 [ 182  395   31 1547  114]
 [  31   14  102   53  491]]
EVAL:   Pre. 0.665 | Rec. 0.685 | F1 0.673 | BEST F1: 0.680 29

Epoch:   32 2022-09-03 23:08:33.983516
[[18106   140    15   159    18]
 [   62 15687   510     0     0]
 [    4   113  4627     0     0]
 [   59     6     0 15732   523]
 [    3     0     2   127  5191]]
TRAIN:  Pre. 0.952 | Rec. 0.972 | F1 0.962
[[1689  255   60  227   63]
 [ 237 1609   91  340   22]
 [  43   60  406   16  108]
 [ 198  434   32 1494  111]
 [  39   15  125   55  457]]
EVAL:   Pre. 0.663 | Rec. 0.679 | F1 0.670 | BEST F1: 0.680 29

Epoch:   33 2022-09-03 23:09:44.569679
[[18103   140    15   160    20]
 [   62 15705   484     8     0]
 [    4   112  4625     0     3]
 [   50     1     0 15769   500]
 [    3     0     3   128  5189]]
TRAIN:  Pre. 0.954 | Rec. 0.973 | F1 0.963
[[1676  223   53  268   74]
 [ 240 1564   87  384   24]
 [  39   60  391   22  121]
 [ 196  360   26 1580  107]
 [  34   13   96   57  491]]
EVAL:   Pre. 0.671 | Rec. 0.687 | F1 0.678 | BEST F1: 0.680 29

Epoch:   34 2022-09-03 23:10:55.585797
[[18084   144    15   175    20]
 [   56 15652   536    15     0]
 [    3    89  4647     0     5]
 [   39     1     0 15715   565]
 [    1     0     2    84  5236]]
TRAIN:  Pre. 0.951 | Rec. 0.974 | F1 0.962
[[1642  226   55  293   78]
 [ 225 1521   94  434   25]
 [  37   51  388   23  134]
 [ 177  320   22 1621  129]
 [  26   11   85   54  515]]
EVAL:   Pre. 0.670 | Rec. 0.690 | F1 0.677 | BEST F1: 0.680 29

Epoch:   35 2022-09-03 23:12:05.646133
[[18131   129    11   152    15]
 [   63 15694   495     7     0]
 [    3    96  4643     0     2]
 [   55     1     0 15735   529]
 [    2     0     3    91  5227]]
TRAIN:  Pre. 0.954 | Rec. 0.975 | F1 0.964
[[1700  233   55  238   68]
 [ 260 1538   88  389   24]
 [  44   56  392   18  123]
 [ 202  381   28 1544  114]
 [  38   13  102   52  486]]
EVAL:   Pre. 0.665 | Rec. 0.683 | F1 0.673 | BEST F1: 0.680 29

Epoch:   36 2022-09-03 23:13:15.894164
[[18115   136    11   161    15]
 [   58 15695   502     4     0]
 [    3    89  4651     0     1]
 [   43     1     0 15750   526]
 [    1     0     2    87  5233]]
TRAIN:  Pre. 0.954 | Rec. 0.975 | F1 0.964
[[1672  237   57  258   70]
 [ 235 1559   90  391   24]
 [  41   55  393   20  124]
 [ 182  381   29 1562  115]
 [  34   14  100   51  492]]
EVAL:   Pre. 0.667 | Rec. 0.686 | F1 0.675 | BEST F1: 0.680 29

Epoch:   37 2022-09-03 23:14:25.861745
[[18100   148    13   161    16]
 [   50 15720   484     5     0]
 [    3    99  4641     0     1]
 [   39     1     0 15779   501]
 [    1     0     2    99  5221]]
TRAIN:  Pre. 0.955 | Rec. 0.975 | F1 0.964
[[1650  252   57  264   71]
 [ 217 1593   86  379   24]
 [  37   58  397   20  121]
 [ 179  370   26 1580  114]
 [  27   15   98   56  495]]
EVAL:   Pre. 0.673 | Rec. 0.690 | F1 0.680 | BEST F1: 0.680 29
[[3480  589  121  702  200]
 [ 506 3023  189  929   42]
 [ 103  132  798   39  246]
 [ 475  887   54 3122  164]
 [  98   33  263  100 1063]]
TEST:   Pre. 0.643 | Rec. 0.656 | F1 0.648

Epoch:   38 2022-09-03 23:16:03.288804
[[18116   137    12   158    15]
 [   51 15712   489     7     0]
 [    3    94  4646     0     1]
 [   43     1     0 15774   502]
 [    1     0     2    96  5224]]
TRAIN:  Pre. 0.955 | Rec. 0.975 | F1 0.965
[[1667  239   57  261   70]
 [ 230 1568   87  390   24]
 [  41   57  394   20  121]
 [ 185  360   24 1584  116]
 [  31   15   95   55  495]]
EVAL:   Pre. 0.672 | Rec. 0.689 | F1 0.679 | BEST F1: 0.680 37

Epoch:   39 2022-09-03 23:17:13.046733
[[18112   140    12   159    15]
 [   50 15709   493     7     0]
 [    3    92  4648     0     1]
 [   42     1     0 15772   505]
 [    1     0     2    94  5226]]
TRAIN:  Pre. 0.955 | Rec. 0.975 | F1 0.964
[[1664  243   57  260   70]
 [ 224 1582   88  381   24]
 [  40   57  395   20  121]
 [ 180  368   26 1581  114]
 [  28   16   97   54  496]]
EVAL:   Pre. 0.673 | Rec. 0.690 | F1 0.680 | BEST F1: 0.680 37
[[3507  573  120  696  196]
 [ 535 2991  192  927   44]
 [ 105  129  797   39  248]
 [ 486  876   55 3120  165]
 [ 100   31  261  100 1065]]
TEST:   Pre. 0.642 | Rec. 0.656 | F1 0.648

Some weights of the model checkpoint at ../model_base/ were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

Inference:

[[18112   140    12   159    15]
 [   50 15709   493     7     0]
 [    3    92  4648     0     1]
 [   42     1     0 15772   505]
 [    1     0     2    94  5226]]
TRAIN:  Pre. 0.955 | Rec. 0.975 | F1 0.964
[[1664  243   57  260   70]
 [ 224 1582   88  381   24]
 [  40   57  395   20  121]
 [ 180  368   26 1581  114]
 [  28   16   97   54  496]]
EVAL:   Pre. 0.673 | Rec. 0.690 | F1 0.680
[[3507  573  120  696  196]
 [ 535 2991  192  927   44]
 [ 105  129  797   39  248]
 [ 486  876   55 3120  165]
 [ 100   31  261  100 1065]]
TEST:   Pre. 0.642 | Rec. 0.656 | F1 0.648

Process finished with exit code 0
