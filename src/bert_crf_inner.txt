ssh://fuyj@115.24.15.21:22/home/fuyj/workspace/venv/torch/bin/python3 -u /home/fuyj/.pycharm_helpers/pydev/pydevd.py --multiproc --qt-support=auto --client 0.0.0.0 --port 42319 --file /home/fuyj/workspace/experiment/ABAM-main/src/run_AURC_token2.py
pydev debugger: process 27961 is connecting

Connected to pydev debugger (build 193.7288.30)
device cuda:0
../models_pre/aurc_in_token.pt
../models_pre/aurc_in_config.json
../models_pre/aurc_in_predictions_dev.json
../models_pre/aurc_in_predictions_test.json
../data/../data/data_dict_bert.json
数据集大小
4396
8 ['abortion', 'cloning', 'death penalty', 'gun control', 'marijuana legalization', 'minimum wage', 'nuclear energy', 'school uniforms']
{'abortion': 415, 'death penalty': 588, 'gun control': 480, 'marijuana legalization': 626, 'minimum wage': 624, 'nuclear energy': 615, 'school uniforms': 705, 'cloning': 343}
Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.
/home/fuyj/workspace/venv/torch/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).
  FutureWarning,
2268 71
307 307
636 636
Some weights of the model checkpoint at ../model_base/ were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
7000
##### DOMAIN: inner , use CRF: True , learning-rate: 1e-05 , DROPOUT: 0.1

Epoch:    0 2022-09-04 13:55:31.976128
/home/fuyj/workspace/venv/torch/lib/python3.6/site-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
[[ 1150   764   338  2217   279]
 [  325 10320  1748   948  3027]
 [  371  2958 12000  1404  2078]
 [  565   293   334  3601   532]
 [  157  5309  1729  1393  7904]]
0.19892019749153192
              precision    recall  f1-score   support

           a       0.45      0.63      0.53      6329
           c       0.02      0.09      0.03      1224
           p       0.02      0.12      0.04      1255

   micro avg       0.20      0.48      0.29      8808
   macro avg       0.16      0.28      0.20      8808
weighted avg       0.33      0.48      0.39      8808

TRAIN:  Pre. 0.533 | Rec. 0.533 | F1 0.199
[[ 172   91   51  284   35]
 [  47 1483  296  111  372]
 [  47  399 1493  171  239]
 [  71   24   48  478   70]
 [  21  582  254  220 1216]]
0.20701443819785467
              precision    recall  f1-score   support

           a       0.47      0.65      0.54       841
           c       0.01      0.06      0.02       166
           p       0.04      0.16      0.06       171

   micro avg       0.21      0.50      0.30      1178
   macro avg       0.17      0.29      0.21      1178
weighted avg       0.34      0.50      0.40      1178

EVAL:   Pre. 0.552 | Rec. 0.554 | F1 0.207 | BEST F1: 0.000 None
[[ 345  234  121  538   82]
 [  99 2853  647  277  855]
 [ 112  860 3306  357  572]
 [ 163   88  109 1050  147]
 [  41 1467  575  438 2215]]
0.2024588981221327
              precision    recall  f1-score   support

           a       0.45      0.62      0.52      1829
           c       0.02      0.10      0.03       352
           p       0.03      0.15      0.05       345

   micro avg       0.20      0.49      0.28      2526
   macro avg       0.17      0.29      0.20      2526
weighted avg       0.34      0.49      0.39      2526

TEST:   Pre. 0.527 | Rec. 0.528 | F1 0.202

Epoch:    1 2022-09-04 13:57:08.287092
[[ 2020   578   357  1581   212]
 [  487 10480  1373   476  3552]
 [  394  1841 13345   765  2466]
 [  564   157   360  3578   666]
 [  156  2943  1351   842 11200]]
0.2638267324512367
              precision    recall  f1-score   support

           a       0.53      0.67      0.59      6329
           c       0.05      0.17      0.08      1224
           p       0.08      0.27      0.12      1255

   micro avg       0.29      0.55      0.38      8808
   macro avg       0.22      0.37      0.26      8808
weighted avg       0.40      0.55      0.45      8808

TRAIN:  Pre. 0.624 | Rec. 0.625 | F1 0.264
[[ 243   75   58  226   31]
 [  66 1418  273   65  487]
 [  69  283 1602   99  296]
 [  66   15   66  447   97]
 [  21  344  221  148 1559]]
0.2506040107869349
              precision    recall  f1-score   support

           a       0.49      0.64      0.56       841
           c       0.04      0.13      0.06       166
           p       0.09      0.29      0.13       171

   micro avg       0.28      0.51      0.36      1178
   macro avg       0.21      0.35      0.25      1178
weighted avg       0.37      0.51      0.43      1178

EVAL:   Pre. 0.599 | Rec. 0.601 | F1 0.251 | BEST F1: 0.207 0
[[ 515  175  138  413   79]
 [ 138 2709  584  152 1148]
 [ 109  522 3531  249  796]
 [ 191   58  138  979  191]
 [  42  931  550  254 2959]]
0.2514977560937116
              precision    recall  f1-score   support

           a       0.50      0.63      0.56      1829
           c       0.05      0.17      0.08       352
           p       0.07      0.26      0.11       345

   micro avg       0.28      0.52      0.36      2526
   macro avg       0.21      0.36      0.25      2526
weighted avg       0.38      0.52      0.43      2526

TEST:   Pre. 0.580 | Rec. 0.579 | F1 0.251

Epoch:    2 2022-09-04 13:58:43.776114
[[ 2751   417   233  1186   161]
 [  680 10866  1089   315  3418]
 [  384  1276 13952   684  2515]
 [  466    65   187  3971   636]
 [  136  1605   957   806 12988]]
0.35364956282977084
              precision    recall  f1-score   support

           a       0.58      0.74      0.65      6329
           c       0.13      0.30      0.18      1224
           p       0.16      0.40      0.23      1255

   micro avg       0.40      0.63      0.49      8808
   macro avg       0.29      0.48      0.35      8808
weighted avg       0.46      0.63      0.52      8808

TRAIN:  Pre. 0.693 | Rec. 0.704 | F1 0.354
[[ 311   62   43  192   25]
 [  89 1347  267   47  559]
 [  79  223 1632   83  332]
 [  69    5   47  487   83]
 [  21  236  176  147 1713]]
0.326869192281499
              precision    recall  f1-score   support

           a       0.55      0.71      0.62       841
           c       0.10      0.22      0.14       166
           p       0.16      0.40      0.23       171

   micro avg       0.37      0.60      0.46      1178
   macro avg       0.27      0.44      0.33      1178
weighted avg       0.43      0.60      0.49      1178

EVAL:   Pre. 0.632 | Rec. 0.644 | F1 0.327 | BEST F1: 0.251 1
[[ 639  141  118  367   55]
 [ 192 2529  557  111 1342]
 [ 108  435 3572  247  845]
 [ 230   25  105 1028  169]
 [  58  672  477  217 3312]]
0.31277646398983355
              precision    recall  f1-score   support

           a       0.55      0.70      0.62      1829
           c       0.09      0.22      0.13       352
           p       0.13      0.37      0.19       345

   micro avg       0.36      0.59      0.45      2526
   macro avg       0.26      0.43      0.31      2526
weighted avg       0.43      0.59      0.49      2526

TEST:   Pre. 0.605 | Rec. 0.613 | F1 0.313

Epoch:    3 2022-09-04 14:00:20.668412
[[ 3634   503   117   451    43]
 [  845 13996   451   103   973]
 [  514  2025 13557   573  2142]
 [  613    77   111  4032   492]
 [  167  2166   551   764 12844]]
0.43903475681895926
              precision    recall  f1-score   support

           a       0.61      0.78      0.69      6329
           c       0.24      0.50      0.33      1224
           p       0.23      0.42      0.30      1255

   micro avg       0.47      0.69      0.56      8808
   macro avg       0.36      0.57      0.44      8808
weighted avg       0.51      0.69      0.58      8808

TRAIN:  Pre. 0.750 | Rec. 0.775 | F1 0.439
[[ 406   70   35  108   14]
 [ 114 1672  176   23  324]
 [  95  343 1540   81  290]
 [ 128   13   36  458   56]
 [  31  493  130  130 1509]]
0.37744181116452485
              precision    recall  f1-score   support

           a       0.57      0.74      0.65       841
           c       0.17      0.39      0.23       166
           p       0.19      0.37      0.25       171

   micro avg       0.42      0.64      0.50      1178
   macro avg       0.31      0.50      0.38      1178
weighted avg       0.46      0.64      0.53      1178

EVAL:   Pre. 0.647 | Rec. 0.668 | F1 0.377 | BEST F1: 0.327 2
[[ 838  164   82  206   30]
 [ 238 3336  345   54  758]
 [ 161  736 3367  211  732]
 [ 329   41   82  985  120]
 [  78 1094  344  205 3015]]
0.3592071180327694
              precision    recall  f1-score   support

           a       0.58      0.73      0.65      1829
           c       0.15      0.37      0.21       352
           p       0.16      0.35      0.22       345

   micro avg       0.40      0.63      0.49      2526
   macro avg       0.30      0.48      0.36      2526
weighted avg       0.46      0.63      0.53      2526

TEST:   Pre. 0.634 | Rec. 0.651 | F1 0.359

Epoch:    4 2022-09-04 14:01:55.921123
[[ 3783   468    84   389    24]
 [  848 14313   372    91   744]
 [  398  1552 14203   603  2055]
 [  295    24    86  4481   439]
 [   65  1004   441   931 14051]]
0.5075580933687954
              precision    recall  f1-score   support

           a       0.63      0.81      0.71      6329
           c       0.34      0.55      0.42      1224
           p       0.31      0.52      0.39      1255

   micro avg       0.53      0.73      0.61      8808
   macro avg       0.43      0.62      0.51      8808
weighted avg       0.55      0.73      0.62      8808

TRAIN:  Pre. 0.793 | Rec. 0.824 | F1 0.508
[[ 393   67   32  125   16]
 [ 108 1618  183   32  368]
 [  90  301 1548   98  312]
 [ 109    9   33  489   51]
 [  30  417  141  147 1558]]
0.389673682592389
              precision    recall  f1-score   support

           a       0.57      0.76      0.65       841
           c       0.18      0.37      0.24       166
           p       0.21      0.38      0.27       171

   micro avg       0.44      0.65      0.52      1178
   macro avg       0.32      0.50      0.39      1178
weighted avg       0.47      0.65      0.54      1178

EVAL:   Pre. 0.647 | Rec. 0.674 | F1 0.390 | BEST F1: 0.377 3
[[ 806  146   90  250   28]
 [ 233 3066  405   76  951]
 [ 142  646 3376  244  799]
 [ 288   33   82 1052  102]
 [  70  908  349  225 3184]]
0.37583146056666306
              precision    recall  f1-score   support

           a       0.59      0.75      0.66      1829
           c       0.17      0.35      0.23       352
           p       0.18      0.37      0.24       345

   micro avg       0.43      0.64      0.51      2526
   macro avg       0.31      0.49      0.38      2526
weighted avg       0.47      0.64      0.54      2526

TEST:   Pre. 0.629 | Rec. 0.651 | F1 0.376

Epoch:    5 2022-09-04 14:03:32.139197
[[ 4130   431   129    55     3]
 [  879 14858   536     8    87]
 [  376  1307 16059   258   811]
 [  583    43   228  4082   389]
 [  126  1631  1242   775 12718]]
0.5224783208346412
              precision    recall  f1-score   support

           a       0.66      0.80      0.72      6329
           c       0.36      0.64      0.46      1224
           p       0.33      0.46      0.38      1255

   micro avg       0.55      0.73      0.63      8808
   macro avg       0.45      0.63      0.52      8808
weighted avg       0.57      0.73      0.64      8808

TRAIN:  Pre. 0.814 | Rec. 0.834 | F1 0.522
[[ 438   65   57   67    6]
 [ 119 1703  286   18  183]
 [ 103  282 1793   43  128]
 [ 186   18   68  381   38]
 [  53  629  253  110 1248]]
0.3842069798252452
              precision    recall  f1-score   support

           a       0.58      0.71      0.64       841
           c       0.18      0.45      0.26       166
           p       0.22      0.30      0.25       171

   micro avg       0.43      0.61      0.51      1178
   macro avg       0.33      0.49      0.38      1178
weighted avg       0.47      0.61      0.53      1178

EVAL:   Pre. 0.648 | Rec. 0.658 | F1 0.384 | BEST F1: 0.390 4

Epoch:    6 2022-09-04 14:04:44.209697
[[ 4170   438    36    97     7]
 [  843 15041   209    17   258]
 [  347  1335 15015   454  1660]
 [   80     7    54  4722   462]
 [   18   235   283   852 15104]]
0.6105630709894806
              precision    recall  f1-score   support

           a       0.67      0.82      0.74      6329
           c       0.50      0.65      0.56      1224
           p       0.47      0.62      0.53      1255

   micro avg       0.61      0.77      0.68      8808
   macro avg       0.54      0.70      0.61      8808
weighted avg       0.62      0.77      0.68      8808

TRAIN:  Pre. 0.848 | Rec. 0.880 | F1 0.611
[[ 413   56   34  108   22]
 [ 120 1564  182   26  417]
 [ 100  281 1583   80  305]
 [ 125   12   35  465   54]
 [  37  434  143  122 1557]]
0.40526807228089456
              precision    recall  f1-score   support

           a       0.59      0.75      0.66       841
           c       0.21      0.40      0.28       166
           p       0.22      0.39      0.28       171

   micro avg       0.45      0.65      0.53      1178
   macro avg       0.34      0.51      0.41      1178
weighted avg       0.48      0.65      0.55      1178

EVAL:   Pre. 0.646 | Rec. 0.671 | F1 0.405 | BEST F1: 0.390 4
[[ 851  125   84  225   35]
 [ 236 3091  367   55  982]
 [ 155  639 3406  210  797]
 [ 303   34   93 1027  100]
 [  57  863  374  206 3236]]
0.4007476200106905
              precision    recall  f1-score   support

           a       0.61      0.75      0.67      1829
           c       0.21      0.38      0.27       352
           p       0.20      0.36      0.26       345

   micro avg       0.47      0.65      0.54      2526
   macro avg       0.34      0.50      0.40      2526
weighted avg       0.50      0.65      0.56      2526

TEST:   Pre. 0.639 | Rec. 0.659 | F1 0.401

Epoch:    7 2022-09-04 14:06:21.842608
[[ 4135   427    96    82     8]
 [  734 14901   474    15   244]
 [  125   540 16650   339  1157]
 [   13     2    76  4758   476]
 [    2    58   407   777 15248]]
0.6494728712555293
              precision    recall  f1-score   support

           a       0.70      0.82      0.76      6329
           c       0.57      0.67      0.61      1224
           p       0.52      0.66      0.58      1255

   micro avg       0.66      0.77      0.71      8808
   macro avg       0.60      0.72      0.65      8808
weighted avg       0.66      0.77      0.71      8808

TRAIN:  Pre. 0.878 | Rec. 0.897 | F1 0.649
[[ 340   51   60  152   30]
 [  86 1325  358   40  500]
 [  63  169 1806   74  237]
 [  69    6   52  506   58]
 [  20  274  242  132 1625]]
0.4087103797012328
              precision    recall  f1-score   support

           a       0.60      0.72      0.66       841
           c       0.21      0.34      0.26       166
           p       0.23      0.46      0.31       171

   micro avg       0.46      0.63      0.53      1178
   macro avg       0.35      0.50      0.41      1178
weighted avg       0.50      0.63      0.55      1178

EVAL:   Pre. 0.651 | Rec. 0.664 | F1 0.409 | BEST F1: 0.405 6
[[ 728  118  152  279   43]
 [ 176 2676  701   68 1110]
 [  86  398 3831  200  692]
 [ 203   25  146 1078  105]
 [  39  578  569  195 3355]]
0.4013215953199767
              precision    recall  f1-score   support

           a       0.62      0.71      0.67      1829
           c       0.21      0.34      0.26       352
           p       0.21      0.41      0.28       345

   micro avg       0.47      0.62      0.54      2526
   macro avg       0.35      0.49      0.40      2526
weighted avg       0.51      0.62      0.56      2526

TEST:   Pre. 0.646 | Rec. 0.651 | F1 0.401

Epoch:    8 2022-09-04 14:07:57.352830
[[ 4256   412    34    43     3]
 [  748 15329   186     6    99]
 [  179   821 16334   313  1164]
 [   12     2    43  4837   431]
 [    0    65   239   782 15406]]
0.6792327297624957
              precision    recall  f1-score   support

           a       0.71      0.84      0.77      6329
           c       0.63      0.71      0.67      1224
           p       0.56      0.66      0.60      1255

   micro avg       0.67      0.79      0.73      8808
   macro avg       0.63      0.74      0.68      8808
weighted avg       0.67      0.79      0.73      8808

TRAIN:  Pre. 0.884 | Rec. 0.909 | F1 0.679
[[ 390   56   43  125   19]
 [  97 1553  229   29  401]
 [  87  240 1671   74  277]
 [ 114   10   40  479   48]
 [  27  392  189  124 1561]]
0.4340590337766808
              precision    recall  f1-score   support

           a       0.61      0.75      0.67       841
           c       0.26      0.40      0.32       166
           p       0.26      0.40      0.32       171

   micro avg       0.49      0.65      0.56      1178
   macro avg       0.38      0.52      0.43      1178
weighted avg       0.51      0.65      0.57      1178

EVAL:   Pre. 0.652 | Rec. 0.675 | F1 0.434 | BEST F1: 0.409 7
[[ 834  127  104  220   35]
 [ 206 3047  500   58  920]
 [ 118  596 3593  207  693]
 [ 280   32  100 1041  104]
 [  54  853  439  183 3207]]
0.4323894889514301
              precision    recall  f1-score   support

           a       0.63      0.75      0.68      1829
           c       0.25      0.40      0.31       352
           p       0.25      0.40      0.30       345

   micro avg       0.50      0.65      0.56      2526
   macro avg       0.38      0.52      0.43      2526
weighted avg       0.52      0.65      0.58      2526

TEST:   Pre. 0.646 | Rec. 0.662 | F1 0.432

Epoch:    9 2022-09-04 14:09:39.236761
[[ 4304   343    39    57     5]
 [  767 15193   221     9   178]
 [  112   537 17066   239   857]
 [    7     2    45  4838   433]
 [    0    21   248   712 15511]]
0.7104241596608452
              precision    recall  f1-score   support

           a       0.73      0.84      0.78      6329
           c       0.67      0.73      0.70      1224
           p       0.60      0.70      0.64      1255

   micro avg       0.70      0.81      0.75      8808
   macro avg       0.67      0.76      0.71      8808
weighted avg       0.70      0.81      0.75      8808

TRAIN:  Pre. 0.896 | Rec. 0.918 | F1 0.710
[[ 338   46   51  169   29]
 [  85 1355  305   39  525]
 [  66  191 1764   69  259]
 [  65    9   50  515   52]
 [  18  291  208  125 1651]]
0.40849013146238616
              precision    recall  f1-score   support

           a       0.61      0.73      0.67       841
           c       0.23      0.33      0.27       166
           p       0.22      0.41      0.29       171

   micro avg       0.47      0.63      0.54      1178
   macro avg       0.35      0.49      0.41      1178
weighted avg       0.50      0.63      0.56      1178

EVAL:   Pre. 0.653 | Rec. 0.667 | F1 0.408 | BEST F1: 0.434 8

Epoch:   10 2022-09-04 14:10:49.677573
[[ 4339   358    31    16     4]
 [  677 15469   176     2    44]
 [  136   559 17278   173   665]
 [   11     1    39  4868   406]
 [    4    30   198   668 15592]]
0.7427974147032796
              precision    recall  f1-score   support

           a       0.75      0.85      0.80      6329
           c       0.71      0.76      0.73      1224
           p       0.67      0.73      0.70      1255

   micro avg       0.73      0.82      0.77      8808
   macro avg       0.71      0.78      0.74      8808
weighted avg       0.73      0.82      0.77      8808

TRAIN:  Pre. 0.908 | Rec. 0.927 | F1 0.743
[[ 389   66   45  119   14]
 [  92 1535  273   28  381]
 [  66  225 1740   76  242]
 [  93    9   48  493   48]
 [  17  343  209  123 1601]]
0.4406422472745129
              precision    recall  f1-score   support

           a       0.62      0.74      0.67       841
           c       0.25      0.38      0.30       166
           p       0.29      0.43      0.35       171

   micro avg       0.50      0.64      0.56      1178
   macro avg       0.39      0.52      0.44      1178
weighted avg       0.52      0.64      0.57      1178

EVAL:   Pre. 0.667 | Rec. 0.686 | F1 0.441 | BEST F1: 0.434 8
[[ 859  116  131  179   35]
 [ 187 3060  614   49  821]
 [ 116  513 3723  196  659]
 [ 282   30  107 1030  108]
 [  49  840  475  175 3197]]
0.45105664727709044
              precision    recall  f1-score   support

           a       0.65      0.74      0.69      1829
           c       0.28      0.42      0.34       352
           p       0.27      0.41      0.33       345

   micro avg       0.52      0.65      0.58      2526
   macro avg       0.40      0.52      0.45      2526
weighted avg       0.54      0.65      0.59      2526

TEST:   Pre. 0.656 | Rec. 0.670 | F1 0.451

Epoch:   11 2022-09-04 14:12:25.371869
[[ 4379   329    21    19     0]
 [  646 15555   137     0    30]
 [  102   490 17449   156   614]
 [    5     1    32  4946   341]
 [    0    23   160   679 15630]]
0.7578245335990279
              precision    recall  f1-score   support

           a       0.76      0.86      0.81      6329
           c       0.75      0.78      0.76      1224
           p       0.68      0.73      0.70      1255

   micro avg       0.75      0.83      0.79      8808
   macro avg       0.73      0.79      0.76      8808
weighted avg       0.75      0.83      0.79      8808

TRAIN:  Pre. 0.915 | Rec. 0.935 | F1 0.758
[[ 393   64   50  116   10]
 [  99 1569  249   23  369]
 [  74  226 1733   73  243]
 [ 108   11   48  481   43]
 [  26  378  205  115 1569]]
0.4347573519452477
              precision    recall  f1-score   support

           a       0.63      0.74      0.68       841
           c       0.24      0.37      0.29       166
           p       0.28      0.42      0.33       171

   micro avg       0.50      0.64      0.56      1178
   macro avg       0.38      0.51      0.43      1178
weighted avg       0.52      0.64      0.58      1178

EVAL:   Pre. 0.663 | Rec. 0.684 | F1 0.435 | BEST F1: 0.441 10

Epoch:   12 2022-09-04 14:13:36.195917
[[ 4311   398    21    17     1]
 [  496 15696   125     1    50]
 [   72   450 17691   119   479]
 [    2     0    24  4944   355]
 [    0     1   162   607 15722]]
0.7791330770792965
              precision    recall  f1-score   support

           a       0.79      0.86      0.82      6329
           c       0.76      0.79      0.78      1224
           p       0.72      0.76      0.74      1255

   micro avg       0.77      0.84      0.80      8808
   macro avg       0.76      0.80      0.78      8808
weighted avg       0.77      0.84      0.80      8808

TRAIN:  Pre. 0.926 | Rec. 0.938 | F1 0.779
[[ 362   71   49  132   19]
 [  70 1544  256   27  412]
 [  60  224 1757   77  231]
 [  79   11   47  501   53]
 [  18  350  219  108 1598]]
0.43051156421468534
              precision    recall  f1-score   support

           a       0.64      0.72      0.68       841
           c       0.22      0.34      0.27       166
           p       0.29      0.43      0.34       171

   micro avg       0.50      0.63      0.56      1178
   macro avg       0.38      0.50      0.43      1178
weighted avg       0.53      0.63      0.57      1178

EVAL:   Pre. 0.671 | Rec. 0.682 | F1 0.431 | BEST F1: 0.441 10

Epoch:   13 2022-09-04 14:14:47.042258
[[ 4471   252    14    11     0]
 [  639 15621    89     0    19]
 [   87   410 17708   126   480]
 [    4     0    23  5048   250]
 [    0     2   106   661 15723]]
0.7907682245311946
              precision    recall  f1-score   support

           a       0.79      0.89      0.83      6329
           c       0.77      0.80      0.79      1224
           p       0.74      0.76      0.75      1255

   micro avg       0.78      0.86      0.82      8808
   macro avg       0.77      0.82      0.79      8808
weighted avg       0.78      0.86      0.82      8808

TRAIN:  Pre. 0.925 | Rec. 0.948 | F1 0.791
[[ 392   62   43  123   13]
 [ 101 1542  253   25  388]
 [  79  229 1721   79  241]
 [ 108    9   46  491   37]
 [  25  384  193  115 1576]]
0.44448529494154326
              precision    recall  f1-score   support

           a       0.63      0.75      0.68       841
           c       0.24      0.38      0.29       166
           p       0.30      0.43      0.35       171

   micro avg       0.51      0.65      0.57      1178
   macro avg       0.39      0.52      0.44      1178
weighted avg       0.53      0.65      0.58      1178

EVAL:   Pre. 0.660 | Rec. 0.684 | F1 0.444 | BEST F1: 0.441 10
[[ 857  113  109  217   24]
 [ 187 3041  567   58  878]
 [ 125  563 3681  192  646]
 [ 288   23   96 1058   92]
 [  48  833  432  198 3225]]
0.4623597906670656
              precision    recall  f1-score   support

           a       0.65      0.77      0.71      1829
           c       0.28      0.41      0.34       352
           p       0.29      0.43      0.35       345

   micro avg       0.54      0.67      0.60      2526
   macro avg       0.41      0.54      0.46      2526
weighted avg       0.55      0.67      0.61      2526

TEST:   Pre. 0.653 | Rec. 0.672 | F1 0.462

Epoch:   14 2022-09-04 14:16:24.846643
[[ 4581   143    16     8     0]
 [  751 15465   121     2    29]
 [   68   282 18043   111   307]
 [    3     0    11  5141   170]
 [    0     2   149   767 15574]]
0.8140314547443621
              precision    recall  f1-score   support

           a       0.78      0.90      0.84      6329
           c       0.81      0.83      0.82      1224
           p       0.77      0.80      0.79      1255

   micro avg       0.78      0.88      0.83      8808
   macro avg       0.79      0.84      0.81      8808
weighted avg       0.78      0.88      0.83      8808

TRAIN:  Pre. 0.925 | Rec. 0.956 | F1 0.814
[[ 383   45   46  148   11]
 [ 114 1493  275   36  391]
 [  72  198 1776   86  217]
 [  83    2   48  528   30]
 [  29  318  240  140 1566]]
0.4396887120964852
              precision    recall  f1-score   support

           a       0.62      0.76      0.69       841
           c       0.24      0.37      0.29       166
           p       0.28      0.45      0.34       171

   micro avg       0.50      0.66      0.57      1178
   macro avg       0.38      0.53      0.44      1178
weighted avg       0.52      0.66      0.58      1178

EVAL:   Pre. 0.661 | Rec. 0.691 | F1 0.440 | BEST F1: 0.444 13

Epoch:   15 2022-09-04 14:17:39.296521
[[ 4539   191    18     0     0]
 [  567 15699    99     0     3]
 [   46   310 18157    56   242]
 [    4     0    19  5127   175]
 [    0     6   124   623 15739]]
0.8283875867159306
              precision    recall  f1-score   support

           a       0.82      0.91      0.86      6329
           c       0.82      0.82      0.82      1224
           p       0.80      0.82      0.81      1255

   micro avg       0.81      0.88      0.85      8808
   macro avg       0.81      0.85      0.83      8808
weighted avg       0.81      0.88      0.85      8808

TRAIN:  Pre. 0.938 | Rec. 0.960 | F1 0.828
[[ 433   64   46   84    6]
 [ 113 1683  262   11  240]
 [  86  270 1769   59  165]
 [ 149   12   53  448   29]
 [  36  541  251  105 1360]]
0.4596956089911632
              precision    recall  f1-score   support

           a       0.64      0.75      0.69       841
           c       0.28      0.46      0.35       166
           p       0.32      0.37      0.34       171

   micro avg       0.52      0.66      0.58      1178
   macro avg       0.41      0.53      0.46      1178
weighted avg       0.54      0.66      0.59      1178

EVAL:   Pre. 0.663 | Rec. 0.681 | F1 0.460 | BEST F1: 0.444 13
[[ 923  124  107  152   14]
 [ 194 3316  559   41  621]
 [ 144  659 3775  147  482]
 [ 385   33  119  949   71]
 [  69 1215  505  164 2783]]
0.4433537083598837
              precision    recall  f1-score   support

           a       0.67      0.76      0.71      1829
           c       0.24      0.43      0.31       352
           p       0.27      0.36      0.31       345

   micro avg       0.53      0.66      0.59      2526
   macro avg       0.39      0.52      0.44      2526
weighted avg       0.55      0.66      0.60      2526

TEST:   Pre. 0.652 | Rec. 0.664 | F1 0.443

Epoch:   16 2022-09-04 14:19:22.195921
[[ 4604   127    15     2     0]
 [  656 15600   108     0     4]
 [   39   211 18297    62   202]
 [    2     0     7  5191   125]
 [    0     1   125   667 15699]]
0.8379019220121044
              precision    recall  f1-score   support

           a       0.81      0.92      0.86      6329
           c       0.83      0.85      0.84      1224
           p       0.79      0.83      0.81      1255

   micro avg       0.81      0.90      0.85      8808
   macro avg       0.81      0.87      0.84      8808
weighted avg       0.81      0.90      0.85      8808

TRAIN:  Pre. 0.938 | Rec. 0.964 | F1 0.838
[[ 419   53   53  102    6]
 [ 109 1581  299   19  301]
 [  83  221 1786   69  190]
 [ 123    8   46  488   26]
 [  36  420  239  121 1477]]
0.45085360001711344
              precision    recall  f1-score   support

           a       0.63      0.76      0.69       841
           c       0.24      0.40      0.30       166
           p       0.31      0.42      0.36       171

   micro avg       0.51      0.66      0.58      1178
   macro avg       0.40      0.53      0.45      1178
weighted avg       0.53      0.66      0.59      1178

EVAL:   Pre. 0.665 | Rec. 0.691 | F1 0.451 | BEST F1: 0.460 15

Epoch:   17 2022-09-04 14:20:32.638160
[[ 4564   168    16     0     0]
 [  414 15824   130     0     0]
 [   24   162 18406    33   186]
 [    4     0    16  5145   160]
 [    0     1   104   492 15895]]
0.8663924629912708
              precision    recall  f1-score   support

           a       0.85      0.92      0.88      6329
           c       0.86      0.88      0.87      1224
           p       0.84      0.85      0.85      1255

   micro avg       0.85      0.90      0.88      8808
   macro avg       0.85      0.88      0.87      8808
weighted avg       0.85      0.90      0.88      8808

TRAIN:  Pre. 0.953 | Rec. 0.967 | F1 0.866
[[ 393   62   59  108   11]
 [  93 1571  320   16  309]
 [  67  200 1824   68  190]
 [ 110   12   60  477   32]
 [  19  401  254  108 1511]]
0.4469648246757198
              precision    recall  f1-score   support

           a       0.65      0.74      0.69       841
           c       0.24      0.37      0.29       166
           p       0.31      0.42      0.36       171

   micro avg       0.52      0.64      0.58      1178
   macro avg       0.40      0.51      0.45      1178
weighted avg       0.55      0.64      0.59      1178

EVAL:   Pre. 0.670 | Rec. 0.685 | F1 0.447 | BEST F1: 0.460 15

Epoch:   18 2022-09-04 14:21:43.137260
[[ 4587   152     8     1     0]
 [  369 15955    40     0     4]
 [   38   242 18209    47   275]
 [    0     0     3  5176   146]
 [    0     1    30   442 16019]]
0.8672570619403493
              precision    recall  f1-score   support

           a       0.86      0.93      0.90      6329
           c       0.86      0.86      0.86      1224
           p       0.85      0.85      0.85      1255

   micro avg       0.86      0.91      0.88      8808
   macro avg       0.86      0.88      0.87      8808
weighted avg       0.86      0.91      0.88      8808

TRAIN:  Pre. 0.956 | Rec. 0.970 | F1 0.867
[[ 379   59   41  136   18]
 [  85 1513  241   30  440]
 [  71  219 1693   89  277]
 [  84    9   39  521   38]
 [  20  356  173  109 1635]]
0.44646135546042043
              precision    recall  f1-score   support

           a       0.65      0.76      0.70       841
           c       0.25      0.37      0.30       166
           p       0.29      0.42      0.34       171

   micro avg       0.52      0.66      0.58      1178
   macro avg       0.40      0.52      0.45      1178
weighted avg       0.54      0.66      0.59      1178

EVAL:   Pre. 0.667 | Rec. 0.688 | F1 0.446 | BEST F1: 0.460 15

Epoch:   19 2022-09-04 14:22:53.380790
[[ 4611   136     0     1     0]
 [  305 16043    15     0     5]
 [   40   284 18183    49   255]
 [    2     0     2  5186   135]
 [    0     2    26   398 16066]]
0.8664989659770272
              precision    recall  f1-score   support

           a       0.88      0.94      0.91      6329
           c       0.85      0.85      0.85      1224
           p       0.84      0.85      0.84      1255

   micro avg       0.87      0.91      0.89      8808
   macro avg       0.86      0.88      0.87      8808
weighted avg       0.87      0.91      0.89      8808

TRAIN:  Pre. 0.960 | Rec. 0.973 | F1 0.866
[[ 401   65   32  122   13]
 [  86 1626  190   23  384]
 [  85  250 1644   94  276]
 [ 105   13   31  504   38]
 [  23  400  156  101 1613]]
0.47824000959356844
              precision    recall  f1-score   support

           a       0.65      0.77      0.70       841
           c       0.30      0.43      0.35       166
           p       0.34      0.43      0.38       171

   micro avg       0.54      0.67      0.60      1178
   macro avg       0.43      0.54      0.48      1178
weighted avg       0.55      0.67      0.61      1178

EVAL:   Pre. 0.671 | Rec. 0.694 | F1 0.478 | BEST F1: 0.460 15
[[ 855  124   83  232   26]
 [ 168 3163  441   58  901]
 [ 141  642 3508  207  709]
 [ 259   31   73 1093  101]
 [  46  850  332  182 3326]]
0.4693965167901304
              precision    recall  f1-score   support

           a       0.66      0.77      0.71      1829
           c       0.28      0.41      0.33       352
           p       0.30      0.45      0.36       345

   micro avg       0.54      0.68      0.60      2526
   macro avg       0.42      0.54      0.47      2526
weighted avg       0.56      0.68      0.61      2526

TEST:   Pre. 0.661 | Rec. 0.679 | F1 0.469

Epoch:   20 2022-09-04 14:24:29.489043
[[ 4680    63     3     2     0]
 [  432 15890    34     2    10]
 [   29   206 18192    47   337]
 [    2     0     0  5207   116]
 [    0     2    20   343 16127]]
0.8674093354701076
              precision    recall  f1-score   support

           a       0.88      0.95      0.91      6329
           c       0.86      0.87      0.87      1224
           p       0.82      0.82      0.82      1255

   micro avg       0.87      0.92      0.89      8808
   macro avg       0.86      0.88      0.87      8808
weighted avg       0.87      0.92      0.89      8808

TRAIN:  Pre. 0.958 | Rec. 0.976 | F1 0.867
[[ 368   43   38  159   25]
 [  94 1420  204   36  555]
 [  70  216 1606  107  350]
 [  69    5   27  545   45]
 [  20  294  123  114 1742]]
0.44517562286528456
              precision    recall  f1-score   support

           a       0.64      0.77      0.70       841
           c       0.25      0.34      0.29       166
           p       0.29      0.44      0.35       171

   micro avg       0.52      0.66      0.58      1178
   macro avg       0.39      0.52      0.45      1178
weighted avg       0.53      0.66      0.59      1178

EVAL:   Pre. 0.665 | Rec. 0.686 | F1 0.445 | BEST F1: 0.478 19

Epoch:   21 2022-09-04 14:25:43.968463
[[ 4656    87     4     1     0]
 [  244 16107    14     0     3]
 [   20   215 18326    42   208]
 [    0     0     1  5231    93]
 [    0     0    22   330 16140]]
0.886455550945661
              precision    recall  f1-score   support

           a       0.90      0.95      0.93      6329
           c       0.87      0.88      0.88      1224
           p       0.85      0.86      0.86      1255

   micro avg       0.89      0.93      0.91      8808
   macro avg       0.88      0.90      0.89      8808
weighted avg       0.89      0.93      0.91      8808

TRAIN:  Pre. 0.968 | Rec. 0.980 | F1 0.886
[[ 382   63   37  135   16]
 [  80 1581  215   28  405]
 [  75  255 1647   96  276]
 [ 105   14   22  505   45]
 [  22  408  149  107 1607]]
0.45344612459937905
              precision    recall  f1-score   support

           a       0.66      0.77      0.71       841
           c       0.27      0.38      0.31       166
           p       0.29      0.41      0.34       171

   micro avg       0.53      0.66      0.59      1178
   macro avg       0.40      0.52      0.45      1178
weighted avg       0.55      0.66      0.60      1178

EVAL:   Pre. 0.663 | Rec. 0.684 | F1 0.453 | BEST F1: 0.478 19

Epoch:   22 2022-09-04 14:26:56.384155
[[ 4686    61     1     0     0]
 [  244 16087    36     0     1]
 [   20   141 18454    23   173]
 [    0     0     3  5261    61]
 [    0     5    25   371 16091]]
0.9076965420694494
              precision    recall  f1-score   support

           a       0.90      0.96      0.93      6329
           c       0.90      0.91      0.91      1224
           p       0.88      0.89      0.89      1255

   micro avg       0.90      0.94      0.92      8808
   macro avg       0.90      0.92      0.91      8808
weighted avg       0.90      0.94      0.92      8808

TRAIN:  Pre. 0.969 | Rec. 0.983 | F1 0.908
[[ 421   60   39  108    5]
 [  91 1660  225   19  314]
 [  92  263 1681   76  237]
 [ 127   10   32  486   36]
 [  29  452  165  106 1541]]
0.46235977885623925
              precision    recall  f1-score   support

           a       0.66      0.78      0.72       841
           c       0.26      0.43      0.33       166
           p       0.30      0.40      0.35       171

   micro avg       0.53      0.68      0.60      1178
   macro avg       0.41      0.54      0.46      1178
weighted avg       0.55      0.68      0.61      1178

EVAL:   Pre. 0.670 | Rec. 0.695 | F1 0.462 | BEST F1: 0.478 19

Epoch:   23 2022-09-04 14:28:07.386951
[[ 4685    60     1     2     0]
 [  172 16156    32     0     8]
 [   12   114 18517    31   137]
 [    0     0     2  5242    81]
 [    0     0    18   261 16213]]
0.9174023273057461
              precision    recall  f1-score   support

           a       0.92      0.97      0.94      6329
           c       0.91      0.91      0.91      1224
           p       0.90      0.90      0.90      1255

   micro avg       0.92      0.95      0.93      8808
   macro avg       0.91      0.92      0.92      8808
weighted avg       0.92      0.95      0.93      8808

TRAIN:  Pre. 0.976 | Rec. 0.985 | F1 0.917
[[ 393   60   37  126   17]
 [  86 1574  219   23  407]
 [  75  231 1685   82  276]
 [ 114   14   30  490   43]
 [  20  419  160  101 1593]]
0.4510610481337989
              precision    recall  f1-score   support

           a       0.66      0.77      0.71       841
           c       0.26      0.39      0.31       166
           p       0.28      0.40      0.33       171

   micro avg       0.53      0.66      0.59      1178
   macro avg       0.40      0.52      0.45      1178
weighted avg       0.55      0.66      0.60      1178

EVAL:   Pre. 0.665 | Rec. 0.685 | F1 0.451 | BEST F1: 0.478 19

Epoch:   24 2022-09-04 14:29:18.006783
[[ 4720    27     1     0     0]
 [  234 16103    31     0     0]
 [   11    89 18624    10    77]
 [    2     0     3  5270    50]
 [    0     2    26   270 16194]]
0.9312170157959047
              precision    recall  f1-score   support

           a       0.92      0.97      0.95      6329
           c       0.92      0.93      0.93      1224
           p       0.92      0.92      0.92      1255

   micro avg       0.92      0.96      0.94      8808
   macro avg       0.92      0.94      0.93      8808
weighted avg       0.92      0.96      0.94      8808

TRAIN:  Pre. 0.976 | Rec. 0.988 | F1 0.931
[[ 399   53   48  119   14]
 [  96 1574  253   21  365]
 [  82  219 1746   72  230]
 [ 123   10   46  478   34]
 [  32  406  215   96 1544]]
0.44278370531325456
              precision    recall  f1-score   support

           a       0.66      0.76      0.70       841
           c       0.23      0.35      0.28       166
           p       0.30      0.42      0.35       171

   micro avg       0.52      0.65      0.58      1178
   macro avg       0.40      0.51      0.44      1178
weighted avg       0.55      0.65      0.59      1178

EVAL:   Pre. 0.662 | Rec. 0.684 | F1 0.443 | BEST F1: 0.478 19

Epoch:   25 2022-09-04 14:30:28.898742
[[ 4697    49     2     0     0]
 [  141 16204    23     0     0]
 [   16   119 18581    12    83]
 [    2     0     2  5244    77]
 [    0     1    51   162 16278]]
0.928962933936361
              precision    recall  f1-score   support

           a       0.95      0.97      0.96      6329
           c       0.91      0.92      0.91      1224
           p       0.91      0.92      0.92      1255

   micro avg       0.94      0.96      0.95      8808
   macro avg       0.92      0.94      0.93      8808
weighted avg       0.94      0.96      0.95      8808

TRAIN:  Pre. 0.982 | Rec. 0.988 | F1 0.929
[[ 420   68   40   93   12]
 [  82 1679  249   15  284]
 [  76  270 1724   70  209]
 [ 125   13   45  450   58]
 [  24  471  201   83 1514]]
0.4559726331844627
              precision    recall  f1-score   support

           a       0.67      0.75      0.71       841
           c       0.27      0.41      0.32       166
           p       0.30      0.37      0.33       171

   micro avg       0.54      0.65      0.59      1178
   macro avg       0.41      0.51      0.46      1178
weighted avg       0.56      0.65      0.60      1178

EVAL:   Pre. 0.675 | Rec. 0.687 | F1 0.456 | BEST F1: 0.478 19

Epoch:   26 2022-09-04 14:31:39.705068
[[ 4730    16     2     0     0]
 [  183 16160    25     0     0]
 [    9    50 18686     9    57]
 [    0     0     3  5292    30]
 [    0     1    35   220 16236]]
0.9451525399404712
              precision    recall  f1-score   support

           a       0.94      0.98      0.96      6329
           c       0.94      0.95      0.95      1224
           p       0.93      0.93      0.93      1255

   micro avg       0.94      0.97      0.95      8808
   macro avg       0.94      0.95      0.95      8808
weighted avg       0.94      0.97      0.95      8808

TRAIN:  Pre. 0.981 | Rec. 0.991 | F1 0.945
[[ 392   52   44  131   14]
 [  93 1508  266   25  417]
 [  79  211 1760   75  224]
 [ 115    7   45  492   32]
 [  25  402  206  110 1550]]
0.436493083835195
              precision    recall  f1-score   support

           a       0.67      0.77      0.71       841
           c       0.22      0.34      0.27       166
           p       0.27      0.40      0.33       171

   micro avg       0.52      0.66      0.58      1178
   macro avg       0.39      0.50      0.44      1178
weighted avg       0.55      0.66      0.60      1178

EVAL:   Pre. 0.658 | Rec. 0.682 | F1 0.436 | BEST F1: 0.478 19

Epoch:   27 2022-09-04 14:32:50.618221
[[ 4727    19     2     0     0]
 [  121 16209    38     0     0]
 [    8    29 18723    10    41]
 [    1     0     1  5287    36]
 [    0     1    46   175 16270]]
0.9531598767229988
              precision    recall  f1-score   support

           a       0.95      0.98      0.97      6329
           c       0.95      0.96      0.95      1224
           p       0.94      0.94      0.94      1255

   micro avg       0.95      0.97      0.96      8808
   macro avg       0.95      0.96      0.95      8808
weighted avg       0.95      0.97      0.96      8808

TRAIN:  Pre. 0.985 | Rec. 0.992 | F1 0.953
[[ 374   57   51  135   16]
 [  83 1505  304   22  395]
 [  63  205 1775   84  222]
 [  94   10   44  504   39]
 [  20  393  228   98 1554]]
0.44367567162643023
              precision    recall  f1-score   support

           a       0.66      0.76      0.71       841
           c       0.25      0.38      0.30       166
           p       0.27      0.42      0.33       171

   micro avg       0.52      0.65      0.58      1178
   macro avg       0.39      0.52      0.44      1178
weighted avg       0.55      0.65      0.59      1178

EVAL:   Pre. 0.664 | Rec. 0.681 | F1 0.444 | BEST F1: 0.478 19

Epoch:   28 2022-09-04 14:34:00.919322
[[ 4730    15     3     0     0]
 [  103 16210    55     0     0]
 [    5    29 18724     7    46]
 [    0     0     2  5305    18]
 [    0     0    28   174 16290]]
0.9574589016243104
              precision    recall  f1-score   support

           a       0.96      0.98      0.97      6329
           c       0.95      0.95      0.95      1224
           p       0.95      0.95      0.95      1255

   micro avg       0.95      0.97      0.96      8808
   macro avg       0.95      0.96      0.96      8808
weighted avg       0.95      0.97      0.96      8808

TRAIN:  Pre. 0.987 | Rec. 0.993 | F1 0.957
[[ 415   64   43   97   14]
 [  87 1625  297   20  280]
 [  72  228 1781   76  192]
 [ 118   12   46  477   38]
 [  28  438  223  103 1501]]
0.46625348723578913
              precision    recall  f1-score   support

           a       0.66      0.76      0.71       841
           c       0.27      0.42      0.33       166
           p       0.32      0.42      0.36       171

   micro avg       0.54      0.66      0.59      1178
   macro avg       0.42      0.53      0.47      1178
weighted avg       0.56      0.66      0.60      1178

EVAL:   Pre. 0.673 | Rec. 0.692 | F1 0.466 | BEST F1: 0.478 19

Epoch:   29 2022-09-04 14:35:14.992621
[[ 4745     3     0     0     0]
 [  135 16213    10     0    10]
 [    9    85 18652     5    60]
 [    0     0     1  5311    13]
 [    0     0    14   171 16307]]
0.9473495608721655
              precision    recall  f1-score   support

           a       0.95      0.99      0.97      6329
           c       0.93      0.93      0.93      1224
           p       0.94      0.94      0.94      1255

   micro avg       0.95      0.97      0.96      8808
   macro avg       0.94      0.95      0.95      8808
weighted avg       0.95      0.97      0.96      8808

TRAIN:  Pre. 0.985 | Rec. 0.994 | F1 0.947
[[ 425   53   38  110    7]
 [ 104 1612  214   21  358]
 [  92  261 1680   79  237]
 [ 130   11   31  487   32]
 [  32  450  160  102 1549]]
0.46574994625364924
              precision    recall  f1-score   support

           a       0.66      0.80      0.72       841
           c       0.27      0.40      0.32       166
           p       0.31      0.41      0.35       171

   micro avg       0.54      0.69      0.60      1178
   macro avg       0.41      0.54      0.47      1178
weighted avg       0.55      0.69      0.61      1178

EVAL:   Pre. 0.666 | Rec. 0.693 | F1 0.466 | BEST F1: 0.478 19

Epoch:   30 2022-09-04 14:36:26.789066
[[ 4746     2     0     0     0]
 [  106 16253     9     0     0]
 [   14    43 18688     8    58]
 [    0     0     0  5312    13]
 [    0     0     9   118 16365]]
0.9625592930124384
              precision    recall  f1-score   support

           a       0.96      0.99      0.98      6329
           c       0.96      0.96      0.96      1224
           p       0.95      0.95      0.95      1255

   micro avg       0.96      0.98      0.97      8808
   macro avg       0.96      0.97      0.96      8808
weighted avg       0.96      0.98      0.97      8808

TRAIN:  Pre. 0.989 | Rec. 0.995 | F1 0.963
[[ 409   61   37  115   11]
 [  94 1599  232   20  364]
 [  78  249 1683   91  248]
 [ 115   13   31  492   40]
 [  29  437  176   96 1555]]
0.4660664182596455
              precision    recall  f1-score   support

           a       0.65      0.78      0.71       841
           c       0.27      0.41      0.33       166
           p       0.31      0.43      0.36       171

   micro avg       0.54      0.67      0.60      1178
   macro avg       0.41      0.54      0.47      1178
weighted avg       0.55      0.67      0.60      1178

EVAL:   Pre. 0.665 | Rec. 0.689 | F1 0.466 | BEST F1: 0.478 19

Epoch:   31 2022-09-04 14:37:40.253412
[[ 4744     3     1     0     0]
 [   73 16279    16     0     0]
 [    6    25 18736     4    40]
 [    0     0     0  5317     8]
 [    0     1    10    95 16386]]
0.9701780544600879
              precision    recall  f1-score   support

           a       0.97      0.99      0.98      6329
           c       0.97      0.97      0.97      1224
           p       0.96      0.96      0.96      1255

   micro avg       0.97      0.98      0.98      8808
   macro avg       0.97      0.97      0.97      8808
weighted avg       0.97      0.98      0.98      8808

TRAIN:  Pre. 0.992 | Rec. 0.996 | F1 0.970
[[ 416   58   40  109   10]
 [  90 1629  251   17  322]
 [  80  245 1722   74  228]
 [ 124   11   38  474   44]
 [  33  432  186   94 1548]]
0.46138949173083765
              precision    recall  f1-score   support

           a       0.66      0.77      0.71       841
           c       0.26      0.40      0.31       166
           p       0.32      0.42      0.36       171

   micro avg       0.54      0.66      0.59      1178
   macro avg       0.41      0.53      0.46      1178
weighted avg       0.56      0.66      0.60      1178

EVAL:   Pre. 0.670 | Rec. 0.691 | F1 0.461 | BEST F1: 0.478 19

Epoch:   32 2022-09-04 14:38:50.978768
[[ 4743     4     1     0     0]
 [   54 16295    19     0     0]
 [    3    13 18767     5    23]
 [    0     0     0  5317     8]
 [    0     0    18    78 16396]]
0.9761606356152649
              precision    recall  f1-score   support

           a       0.98      0.99      0.99      6329
           c       0.97      0.98      0.97      1224
           p       0.97      0.97      0.97      1255

   micro avg       0.98      0.99      0.98      8808
   macro avg       0.97      0.98      0.98      8808
weighted avg       0.98      0.99      0.98      8808

TRAIN:  Pre. 0.994 | Rec. 0.997 | F1 0.976
[[ 397   53   42  125   16]
 [  79 1518  283   24  405]
 [  73  206 1762   70  238]
 [ 104   11   49  485   42]
 [  24  403  227   94 1545]]
0.4502619819668679
              precision    recall  f1-score   support

           a       0.68      0.76      0.72       841
           c       0.25      0.39      0.31       166
           p       0.27      0.42      0.33       171

   micro avg       0.53      0.66      0.59      1178
   macro avg       0.40      0.52      0.45      1178
weighted avg       0.56      0.66      0.60      1178

EVAL:   Pre. 0.664 | Rec. 0.682 | F1 0.450 | BEST F1: 0.478 19

Epoch:   33 2022-09-04 14:40:02.517423
[[ 4746     2     0     0     0]
 [   49 16314     5     0     0]
 [    5    36 18730     4    36]
 [    0     0     0  5314    11]
 [    0     0     4    57 16431]]
0.9741304439578844
              precision    recall  f1-score   support

           a       0.98      0.99      0.99      6329
           c       0.97      0.97      0.97      1224
           p       0.97      0.96      0.97      1255

   micro avg       0.98      0.99      0.98      8808
   macro avg       0.97      0.98      0.97      8808
weighted avg       0.98      0.99      0.98      8808

TRAIN:  Pre. 0.994 | Rec. 0.997 | F1 0.974
[[ 406   67   33  111   16]
 [  80 1625  211   22  371]
 [  78  246 1680   82  263]
 [ 109   16   25  493   48]
 [  18  429  162   95 1589]]
0.47137681128547243
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.28      0.42      0.34       166
           p       0.31      0.42      0.36       171

   micro avg       0.55      0.67      0.60      1178
   macro avg       0.42      0.54      0.47      1178
weighted avg       0.57      0.67      0.61      1178

EVAL:   Pre. 0.675 | Rec. 0.693 | F1 0.471 | BEST F1: 0.478 19

Epoch:   34 2022-09-04 14:41:14.605275
[[ 4747     0     1     0     0]
 [   49 16303    16     0     0]
 [    2    19 18774     3    13]
 [    0     0     1  5316     8]
 [    0     0    18    43 16431]]
0.9811689642654283
              precision    recall  f1-score   support

           a       0.98      0.99      0.99      6329
           c       0.98      0.98      0.98      1224
           p       0.98      0.98      0.98      1255

   micro avg       0.98      0.99      0.99      8808
   macro avg       0.98      0.98      0.98      8808
weighted avg       0.98      0.99      0.99      8808

TRAIN:  Pre. 0.995 | Rec. 0.998 | F1 0.981
[[ 424   61   43   92   13]
 [  91 1641  264   16  297]
 [  73  232 1780   58  206]
 [ 121   12   48  461   49]
 [  28  441  232   89 1503]]
0.47909779059538704
              precision    recall  f1-score   support

           a       0.67      0.76      0.71       841
           c       0.30      0.43      0.35       166
           p       0.33      0.43      0.38       171

   micro avg       0.55      0.66      0.60      1178
   macro avg       0.43      0.54      0.48      1178
weighted avg       0.57      0.66      0.61      1178

EVAL:   Pre. 0.677 | Rec. 0.692 | F1 0.479 | BEST F1: 0.478 19
[[ 896  119  114  169   22]
 [ 171 3164  630   43  723]
 [ 124  526 3859  155  543]
 [ 291   37  122 1009   98]
 [  51  916  544  143 3082]]
0.46457126809146976
              precision    recall  f1-score   support

           a       0.69      0.75      0.72      1829
           c       0.29      0.44      0.35       352
           p       0.28      0.40      0.33       345

   micro avg       0.55      0.66      0.60      2526
   macro avg       0.42      0.53      0.46      2526
weighted avg       0.58      0.66      0.61      2526

TEST:   Pre. 0.667 | Rec. 0.677 | F1 0.465

Epoch:   35 2022-09-04 14:42:51.310027
[[ 4748     0     0     0     0]
 [   44 16316     8     0     0]
 [    3    20 18774     1    13]
 [    0     0     1  5320     4]
 [    0     0    16    58 16418]]
0.981201358627457
              precision    recall  f1-score   support

           a       0.98      0.99      0.99      6329
           c       0.98      0.98      0.98      1224
           p       0.97      0.98      0.98      1255

   micro avg       0.98      0.99      0.99      8808
   macro avg       0.98      0.98      0.98      8808
weighted avg       0.98      0.99      0.99      8808

TRAIN:  Pre. 0.995 | Rec. 0.998 | F1 0.981
[[ 425   62   42   92   12]
 [  86 1666  251   16  290]
 [  83  249 1728   73  216]
 [ 124   13   43  469   42]
 [  27  456  219   95 1496]]
0.4755678915527328
              precision    recall  f1-score   support

           a       0.67      0.76      0.71       841
           c       0.29      0.43      0.35       166
           p       0.32      0.42      0.37       171

   micro avg       0.55      0.67      0.60      1178
   macro avg       0.43      0.54      0.48      1178
weighted avg       0.56      0.67      0.61      1178

EVAL:   Pre. 0.673 | Rec. 0.692 | F1 0.476 | BEST F1: 0.479 34

Epoch:   36 2022-09-04 14:44:02.664013
[[ 4748     0     0     0     0]
 [   29 16333     6     0     0]
 [    3    29 18742     4    33]
 [    0     0     0  5320     5]
 [    0     0    12    25 16455]]
0.9794535800723402
              precision    recall  f1-score   support

           a       0.99      1.00      0.99      6329
           c       0.98      0.98      0.98      1224
           p       0.97      0.97      0.97      1255

   micro avg       0.98      0.99      0.99      8808
   macro avg       0.98      0.98      0.98      8808
weighted avg       0.98      0.99      0.99      8808

TRAIN:  Pre. 0.997 | Rec. 0.998 | F1 0.979
[[ 411   64   34  105   19]
 [  78 1622  192   20  397]
 [  73  251 1655   84  286]
 [ 105   16   24  495   51]
 [  21  429  134   92 1617]]
0.47662952117971535
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.30      0.44      0.36       166
           p       0.30      0.43      0.35       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.42      0.55      0.48      1178
weighted avg       0.56      0.68      0.61      1178

EVAL:   Pre. 0.679 | Rec. 0.696 | F1 0.477 | BEST F1: 0.479 34

Epoch:   37 2022-09-04 14:45:13.266299
[[ 4748     0     0     0     0]
 [   37 16321    10     0     0]
 [    2     6 18791     2    10]
 [    0     0     3  5318     4]
 [    0     0    18    24 16450]]
0.9860169385624106
              precision    recall  f1-score   support

           a       0.99      1.00      0.99      6329
           c       0.99      0.99      0.99      1224
           p       0.98      0.98      0.98      1255

   micro avg       0.99      0.99      0.99      8808
   macro avg       0.98      0.99      0.99      8808
weighted avg       0.99      0.99      0.99      8808

TRAIN:  Pre. 0.997 | Rec. 0.998 | F1 0.986
[[ 394   53   45  124   17]
 [  82 1498  267   30  432]
 [  64  198 1767   77  243]
 [  88   12   46  504   41]
 [  22  341  229   98 1603]]
0.45048396246629857
              precision    recall  f1-score   support

           a       0.67      0.76      0.71       841
           c       0.26      0.38      0.31       166
           p       0.27      0.42      0.33       171

   micro avg       0.53      0.66      0.59      1178
   macro avg       0.40      0.52      0.45      1178
weighted avg       0.55      0.66      0.60      1178

EVAL:   Pre. 0.672 | Rec. 0.690 | F1 0.450 | BEST F1: 0.479 34

Epoch:   38 2022-09-04 14:46:24.244504
[[ 4748     0     0     0     0]
 [   22 16339     7     0     0]
 [    2     8 18786     3    12]
 [    0     0     1  5320     4]
 [    0     0     5    18 16469]]
0.9898616477341154
              precision    recall  f1-score   support

           a       0.99      1.00      0.99      6329
           c       0.99      0.99      0.99      1224
           p       0.99      0.98      0.99      1255

   micro avg       0.99      0.99      0.99      8808
   macro avg       0.99      0.99      0.99      8808
weighted avg       0.99      0.99      0.99      8808

TRAIN:  Pre. 0.998 | Rec. 0.999 | F1 0.990
[[ 414   56   38  108   17]
 [  81 1583  235   22  388]
 [  67  221 1730   82  249]
 [  99   13   39  500   40]
 [  27  402  184  101 1579]]
0.46402037768441823
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.27      0.41      0.33       166
           p       0.29      0.42      0.35       171

   micro avg       0.54      0.67      0.60      1178
   macro avg       0.41      0.53      0.46      1178
weighted avg       0.56      0.67      0.61      1178

EVAL:   Pre. 0.677 | Rec. 0.698 | F1 0.464 | BEST F1: 0.479 34

Epoch:   39 2022-09-04 14:47:35.475703
[[ 4748     0     0     0     0]
 [   25 16337     6     0     0]
 [    3     9 18771     2    26]
 [    0     0     0  5322     3]
 [    0     0     2    22 16468]]
0.9869159060764517
              precision    recall  f1-score   support

           a       0.99      1.00      0.99      6329
           c       0.99      0.99      0.99      1224
           p       0.98      0.98      0.98      1255

   micro avg       0.99      0.99      0.99      8808
   macro avg       0.99      0.99      0.99      8808
weighted avg       0.99      0.99      0.99      8808

TRAIN:  Pre. 0.997 | Rec. 0.999 | F1 0.987
[[ 410   55   37  119   12]
 [  85 1583  219   22  400]
 [  67  233 1682   88  279]
 [  97   12   32  510   40]
 [  28  400  156   97 1612]]
0.4679264513469417
              precision    recall  f1-score   support

           a       0.67      0.79      0.72       841
           c       0.28      0.41      0.33       166
           p       0.30      0.42      0.35       171

   micro avg       0.54      0.68      0.60      1178
   macro avg       0.42      0.54      0.47      1178
weighted avg       0.56      0.68      0.61      1178

EVAL:   Pre. 0.676 | Rec. 0.698 | F1 0.468 | BEST F1: 0.479 34

Epoch:   40 2022-09-04 14:48:48.054273
[[ 4747     1     0     0     0]
 [   17 16350     1     0     0]
 [    3    13 18774     5    16]
 [    0     0     0  5322     3]
 [    0     0     5    12 16475]]
0.9881276765993037
              precision    recall  f1-score   support

           a       0.99      1.00      1.00      6329
           c       0.99      0.99      0.99      1224
           p       0.98      0.98      0.98      1255

   micro avg       0.99      0.99      0.99      8808
   macro avg       0.99      0.99      0.99      8808
weighted avg       0.99      0.99      0.99      8808

TRAIN:  Pre. 0.998 | Rec. 0.999 | F1 0.988
[[ 398   61   36  125   13]
 [  78 1588  215   22  406]
 [  73  247 1679   90  260]
 [  98   15   25  506   47]
 [  24  402  153   98 1616]]
0.4737921514904808
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.29      0.40      0.33       166
           p       0.31      0.43      0.36       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.42      0.54      0.47      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.674 | Rec. 0.694 | F1 0.474 | BEST F1: 0.479 34

Epoch:   41 2022-09-04 14:49:59.135751
[[ 4747     1     0     0     0]
 [   12 16340    16     0     0]
 [    1     0 18805     2     3]
 [    0     0     0  5324     1]
 [    0     0    11    15 16466]]
0.992083670306488
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       0.99      0.99      0.99      1224
           p       0.99      0.99      0.99      1255

   micro avg       0.99      1.00      0.99      8808
   macro avg       0.99      0.99      0.99      8808
weighted avg       0.99      1.00      0.99      8808

TRAIN:  Pre. 0.998 | Rec. 0.999 | F1 0.992
[[ 380   58   47  131   17]
 [  80 1497  303   22  407]
 [  60  201 1790   73  225]
 [  82   10   47  504   48]
 [  18  323  255  100 1597]]
0.44368552896103025
              precision    recall  f1-score   support

           a       0.67      0.75      0.71       841
           c       0.25      0.36      0.29       166
           p       0.28      0.42      0.33       171

   micro avg       0.53      0.65      0.58      1178
   macro avg       0.40      0.51      0.44      1178
weighted avg       0.55      0.65      0.59      1178

EVAL:   Pre. 0.673 | Rec. 0.687 | F1 0.444 | BEST F1: 0.479 34

Epoch:   42 2022-09-04 14:51:13.544123
[[ 4747     0     1     0     0]
 [    7 16349    12     0     0]
 [    1     3 18802     1     4]
 [    0     0     0  5323     2]
 [    0     0    10    11 16471]]
0.9924870126177582
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       0.99      0.99      0.99      1224
           p       0.99      0.99      0.99      1255

   micro avg       0.99      1.00      1.00      8808
   macro avg       0.99      0.99      0.99      8808
weighted avg       0.99      1.00      1.00      8808

TRAIN:  Pre. 0.999 | Rec. 0.999 | F1 0.992
[[ 400   64   45  110   14]
 [  74 1597  269   22  347]
 [  60  211 1779   75  224]
 [  98   13   42  495   43]
 [  21  403  226   95 1548]]
0.4671741873865413
              precision    recall  f1-score   support

           a       0.67      0.76      0.71       841
           c       0.29      0.42      0.34       166
           p       0.30      0.42      0.35       171

   micro avg       0.55      0.66      0.60      1178
   macro avg       0.42      0.53      0.47      1178
weighted avg       0.57      0.66      0.61      1178

EVAL:   Pre. 0.679 | Rec. 0.694 | F1 0.467 | BEST F1: 0.479 34

Epoch:   43 2022-09-04 14:52:24.424681
[[ 4748     0     0     0     0]
 [    7 16360     0     0     1]
 [    2    15 18776     1    17]
 [    0     0     0  5322     3]
 [    0     0     1     7 16484]]
0.9901401329251335
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       0.99      0.99      0.99      1224
           p       0.99      0.99      0.99      1255

   micro avg       0.99      0.99      0.99      8808
   macro avg       0.99      0.99      0.99      8808
weighted avg       0.99      0.99      0.99      8808

TRAIN:  Pre. 0.999 | Rec. 0.999 | F1 0.990
[[ 370   63   36  144   20]
 [  73 1535  202   23  476]
 [  59  213 1672   96  309]
 [  88    9   27  515   52]
 [  20  351  139   94 1689]]
0.47033738666611186
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.30      0.40      0.35       166
           p       0.29      0.44      0.35       171

   micro avg       0.55      0.67      0.60      1178
   macro avg       0.42      0.54      0.47      1178
weighted avg       0.56      0.67      0.61      1178

EVAL:   Pre. 0.675 | Rec. 0.689 | F1 0.470 | BEST F1: 0.479 34

Epoch:   44 2022-09-04 14:53:36.485001
[[ 4748     0     0     0     0]
 [    2 16365     1     0     0]
 [    1     4 18799     2     5]
 [    0     0     0  5323     2]
 [    0     0     2     4 16486]]
0.9955281475318186
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       0.99      0.99      0.99      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 0.999 | Rec. 1.000 | F1 0.996
[[ 385   70   37  121   20]
 [  74 1592  222   22  399]
 [  65  225 1713   84  262]
 [  90   15   29  503   54]
 [  18  375  173   89 1638]]
0.46493160150449153
              precision    recall  f1-score   support

           a       0.68      0.76      0.72       841
           c       0.29      0.43      0.35       166
           p       0.28      0.42      0.33       171

   micro avg       0.54      0.66      0.60      1178
   macro avg       0.41      0.54      0.46      1178
weighted avg       0.56      0.66      0.61      1178

EVAL:   Pre. 0.680 | Rec. 0.694 | F1 0.465 | BEST F1: 0.479 34

Epoch:   45 2022-09-04 14:54:46.894928
[[ 4748     0     0     0     0]
 [    2 16365     1     0     0]
 [    0     7 18790     2    12]
 [    0     0     0  5323     2]
 [    0     0     2     3 16487]]
0.9934357089713713
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       0.99      0.99      0.99      1224
           p       0.99      0.99      0.99      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       0.99      0.99      0.99      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 0.999 | Rec. 1.000 | F1 0.993
[[ 395   77   40  104   17]
 [  74 1678  208   18  331]
 [  71  259 1679   72  268]
 [ 122   15   32  466   56]
 [  23  456  153   81 1580]]
0.4648379931425077
              precision    recall  f1-score   support

           a       0.68      0.75      0.71       841
           c       0.29      0.43      0.35       166
           p       0.29      0.40      0.34       171

   micro avg       0.54      0.65      0.59      1178
   macro avg       0.42      0.53      0.46      1178
weighted avg       0.57      0.65      0.60      1178

EVAL:   Pre. 0.675 | Rec. 0.686 | F1 0.465 | BEST F1: 0.479 34

Epoch:   46 2022-09-04 14:55:57.096673
[[ 4748     0     0     0     0]
 [    4 16360     4     0     0]
 [    0     2 18808     1     0]
 [    0     0     0  5324     1]
 [    0     0     7     5 16480]]
0.995774065326405
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       0.99      0.99      0.99      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 0.999 | Rec. 1.000 | F1 0.996
[[ 386   53   46  132   16]
 [  76 1542  252   23  416]
 [  55  200 1765   80  249]
 [  91    7   37  507   49]
 [  25  348  217   95 1608]]
0.4651896482514906
              precision    recall  f1-score   support

           a       0.67      0.76      0.71       841
           c       0.30      0.42      0.35       166
           p       0.28      0.42      0.34       171

   micro avg       0.54      0.67      0.60      1178
   macro avg       0.41      0.53      0.47      1178
weighted avg       0.56      0.67      0.61      1178

EVAL:   Pre. 0.676 | Rec. 0.693 | F1 0.465 | BEST F1: 0.479 34

Epoch:   47 2022-09-04 14:57:07.249144
[[ 4748     0     0     0     0]
 [    3 16365     0     0     0]
 [    0     0 18806     1     4]
 [    0     0     0  5324     1]
 [    0     0     7     2 16483]]
0.9965805824457422
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       0.99      0.99      0.99      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.997
[[ 406   63   39  107   18]
 [  74 1606  232   20  377]
 [  58  218 1726   87  260]
 [  98   13   30  496   54]
 [  21  373  182   88 1629]]
0.477846923960179
              precision    recall  f1-score   support

           a       0.68      0.76      0.72       841
           c       0.30      0.43      0.35       166
           p       0.31      0.44      0.36       171

   micro avg       0.55      0.67      0.60      1178
   macro avg       0.43      0.54      0.48      1178
weighted avg       0.57      0.67      0.61      1178

EVAL:   Pre. 0.685 | Rec. 0.700 | F1 0.478 | BEST F1: 0.479 34

Epoch:   48 2022-09-04 14:58:17.545695
[[ 4748     0     0     0     0]
 [    1 16366     1     0     0]
 [    0     4 18801     1     5]
 [    0     0     0  5324     1]
 [    0     0     5     4 16483]]
0.9960745413742408
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       0.99      0.99      0.99      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.996
[[ 404   67   37  104   21]
 [  77 1640  222   19  351]
 [  61  225 1729   80  254]
 [  97   10   34  497   53]
 [  19  378  193   89 1614]]
0.48573575131832464
              precision    recall  f1-score   support

           a       0.68      0.77      0.72       841
           c       0.30      0.44      0.36       166
           p       0.32      0.45      0.38       171

   micro avg       0.56      0.67      0.61      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.58      0.67      0.62      1178

EVAL:   Pre. 0.687 | Rec. 0.702 | F1 0.486 | BEST F1: 0.479 34
[[ 837  131   98  225   29]
 [ 143 3088  570   45  885]
 [ 122  542 3700  188  655]
 [ 283   36   89 1036  113]
 [  45  913  426  135 3217]]
0.46959902077554166
              precision    recall  f1-score   support

           a       0.69      0.76      0.72      1829
           c       0.27      0.41      0.33       352
           p       0.29      0.45      0.36       345

   micro avg       0.55      0.67      0.60      2526
   macro avg       0.42      0.54      0.47      2526
weighted avg       0.58      0.67      0.62      2526

TEST:   Pre. 0.658 | Rec. 0.668 | F1 0.470

Epoch:   49 2022-09-04 14:59:56.331193
[[ 4748     0     0     0     0]
 [    3 16362     3     0     0]
 [    0     3 18807     0     1]
 [    0     0     0  5324     1]
 [    0     0     3     4 16485]]
0.9969394902875693
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.997
[[ 411   54   42  113   13]
 [  89 1634  219   20  347]
 [  68  236 1702   89  254]
 [  99    7   35  506   44]
 [  24  379  165  100 1625]]
0.47407763725736185
              precision    recall  f1-score   support

           a       0.66      0.78      0.72       841
           c       0.29      0.43      0.35       166
           p       0.31      0.44      0.36       171

   micro avg       0.54      0.68      0.60      1178
   macro avg       0.42      0.55      0.47      1178
weighted avg       0.56      0.68      0.61      1178

EVAL:   Pre. 0.682 | Rec. 0.704 | F1 0.474 | BEST F1: 0.486 48

Epoch:   50 2022-09-04 15:01:07.809118
[[ 4748     0     0     0     0]
 [    1 16365     2     0     0]
 [    0     5 18801     0     5]
 [    0     0     0  5323     2]
 [    0     0     1     2 16489]]
0.9963472958047174
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       0.99      1.00      0.99      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.996
[[ 399   61   33  119   21]
 [  82 1607  193   20  407]
 [  69  244 1656   92  288]
 [  89    8   28  512   54]
 [  22  343  149   94 1685]]
0.48485431944212687
              precision    recall  f1-score   support

           a       0.66      0.77      0.71       841
           c       0.32      0.43      0.37       166
           p       0.32      0.45      0.37       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.701 | F1 0.485 | BEST F1: 0.486 48

Epoch:   51 2022-09-04 15:02:18.615614
[[ 4748     0     0     0     0]
 [    0 16365     3     0     0]
 [    0     5 18804     1     1]
 [    0     0     0  5323     2]
 [    0     0     2     1 16489]]
0.9965792560014521
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       0.99      0.99      0.99      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.997
[[ 411   68   39   99   16]
 [  80 1667  214   19  329]
 [  73  249 1699   87  241]
 [ 111   12   31  496   41]
 [  23  417  166  102 1585]]
0.47369908363616336
              precision    recall  f1-score   support

           a       0.66      0.77      0.71       841
           c       0.30      0.46      0.36       166
           p       0.29      0.43      0.35       171

   micro avg       0.54      0.67      0.60      1178
   macro avg       0.42      0.55      0.47      1178
weighted avg       0.56      0.67      0.61      1178

EVAL:   Pre. 0.681 | Rec. 0.701 | F1 0.474 | BEST F1: 0.486 48

Epoch:   52 2022-09-04 15:03:29.603855
[[ 4748     0     0     0     0]
 [    1 16366     1     0     0]
 [    1     6 18798     1     5]
 [    0     0     0  5325     0]
 [    0     0     1     1 16490]]
0.9958901856314536
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       0.99      0.99      0.99      1224
           p       0.99      0.99      0.99      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.996
[[ 382   54   35  143   19]
 [  81 1558  184   24  462]
 [  70  243 1643   99  294]
 [  87    6   26  530   42]
 [  22  340  137   97 1697]]
0.47521230339299336
              precision    recall  f1-score   support

           a       0.67      0.79      0.72       841
           c       0.29      0.40      0.33       166
           p       0.31      0.46      0.37       171

   micro avg       0.55      0.69      0.61      1178
   macro avg       0.42      0.55      0.48      1178
weighted avg       0.56      0.69      0.62      1178

EVAL:   Pre. 0.677 | Rec. 0.697 | F1 0.475 | BEST F1: 0.486 48

Epoch:   53 2022-09-04 15:04:40.684761
[[ 4748     0     0     0     0]
 [    1 16362     5     0     0]
 [    1     0 18808     0     2]
 [    0     0     0  5325     0]
 [    0     0     1     1 16490]]
0.9974125313457204
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       0.99      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.997
[[ 385   64   38  125   21]
 [  73 1566  211   21  438]
 [  60  214 1701   87  287]
 [  84    8   32  517   50]
 [  18  333  157   94 1691]]
0.48399728646680407
              precision    recall  f1-score   support

           a       0.68      0.77      0.72       841
           c       0.31      0.41      0.36       166
           p       0.32      0.46      0.38       171

   micro avg       0.56      0.67      0.61      1178
   macro avg       0.44      0.55      0.48      1178
weighted avg       0.57      0.67      0.62      1178

EVAL:   Pre. 0.685 | Rec. 0.699 | F1 0.484 | BEST F1: 0.486 48

Epoch:   54 2022-09-04 15:05:51.635843
[[ 4748     0     0     0     0]
 [    0 16363     5     0     0]
 [    0     0 18810     1     0]
 [    0     0     0  5324     1]
 [    0     0     1     1 16490]]
0.9983580188185837
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.998
[[ 404   59   41  112   17]
 [  80 1594  226   20  389]
 [  61  218 1726   82  262]
 [  96   11   32  498   54]
 [  21  373  171   88 1640]]
0.4778895889714967
              precision    recall  f1-score   support

           a       0.68      0.77      0.72       841
           c       0.30      0.43      0.35       166
           p       0.30      0.45      0.36       171

   micro avg       0.55      0.67      0.60      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.67      0.62      1178

EVAL:   Pre. 0.684 | Rec. 0.700 | F1 0.478 | BEST F1: 0.486 48

Epoch:   55 2022-09-04 15:07:02.137823
[[ 4748     0     0     0     0]
 [    0 16367     1     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     3     1 16488]]
0.9988781884816283
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 408   66   40  104   15]
 [  76 1632  230   18  353]
 [  65  243 1748   70  223]
 [ 105   13   40  491   42]
 [  23  417  191   91 1571]]
0.48644623490583827
              precision    recall  f1-score   support

           a       0.68      0.77      0.72       841
           c       0.31      0.44      0.36       166
           p       0.33      0.44      0.38       171

   micro avg       0.56      0.67      0.61      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.58      0.67      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.698 | F1 0.486 | BEST F1: 0.486 48
[[ 859  122  110  212   17]
 [ 155 3134  569   46  827]
 [ 117  547 3751  181  611]
 [ 286   43  102 1033   93]
 [  49  942  470  139 3136]]
0.47414805159166334
              precision    recall  f1-score   support

           a       0.70      0.76      0.73      1829
           c       0.28      0.44      0.34       352
           p       0.29      0.44      0.35       345

   micro avg       0.55      0.67      0.61      2526
   macro avg       0.42      0.55      0.47      2526
weighted avg       0.58      0.67      0.62      2526

TEST:   Pre. 0.660 | Rec. 0.672 | F1 0.474

Epoch:   56 2022-09-04 15:08:37.733212
[[ 4748     0     0     0     0]
 [    0 16367     1     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9994620645956479
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 403   69   40  104   17]
 [  75 1645  225   18  346]
 [  67  245 1714   70  253]
 [  98   16   34  494   49]
 [  21  405  180   88 1599]]
0.4726987368591889
              precision    recall  f1-score   support

           a       0.67      0.76      0.71       841
           c       0.30      0.44      0.36       166
           p       0.29      0.43      0.35       171

   micro avg       0.54      0.67      0.60      1178
   macro avg       0.42      0.54      0.47      1178
weighted avg       0.56      0.67      0.61      1178

EVAL:   Pre. 0.685 | Rec. 0.698 | F1 0.473 | BEST F1: 0.486 55

Epoch:   57 2022-09-04 15:09:50.573653
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     1 18810     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     1 16490]]
0.9994093969809642
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 404   63   35  116   15]
 [  77 1636  220   19  357]
 [  63  217 1714   90  265]
 [  94   11   31  507   48]
 [  24  370  173   96 1630]]
0.4897666164777914
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.33      0.47      0.39       166
           p       0.30      0.44      0.36       171

   micro avg       0.55      0.69      0.61      1178
   macro avg       0.43      0.56      0.49      1178
weighted avg       0.57      0.69      0.62      1178

EVAL:   Pre. 0.686 | Rec. 0.704 | F1 0.490 | BEST F1: 0.486 55
[[ 844  121   92  236   27]
 [ 156 3104  525   48  898]
 [ 124  543 3678  196  666]
 [ 275   34   83 1073   92]
 [  47  902  417  157 3213]]
0.47947504226438725
              precision    recall  f1-score   support

           a       0.69      0.77      0.73      1829
           c       0.29      0.42      0.34       352
           p       0.31      0.45      0.36       345

   micro avg       0.56      0.68      0.62      2526
   macro avg       0.43      0.55      0.48      2526
weighted avg       0.58      0.68      0.63      2526

TEST:   Pre. 0.659 | Rec. 0.674 | F1 0.479

Epoch:   58 2022-09-04 15:11:33.953657
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     1 18809     0     1]
 [    0     0     0  5325     0]
 [    0     0     1     1 16490]]
0.9991437927312962
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 418   59   39  109    8]
 [  86 1647  217   19  340]
 [  72  256 1710   71  240]
 [ 116   13   37  485   40]
 [  29  419  189   94 1562]]
0.48756421096655117
              precision    recall  f1-score   support

           a       0.68      0.78      0.73       841
           c       0.32      0.45      0.37       166
           p       0.32      0.43      0.37       171

   micro avg       0.56      0.69      0.62      1178
   macro avg       0.44      0.56      0.49      1178
weighted avg       0.57      0.69      0.62      1178

EVAL:   Pre. 0.677 | Rec. 0.697 | F1 0.488 | BEST F1: 0.490 57

Epoch:   59 2022-09-04 15:12:45.569317
[[ 4748     0     0     0     0]
 [    0 16366     2     0     0]
 [    0     0 18810     0     1]
 [    0     0     0  5325     0]
 [    0     0     1     1 16490]]
0.9990077939553963
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 415   62   39  104   13]
 [  82 1659  201   18  349]
 [  75  261 1686   74  253]
 [ 123   15   29  480   44]
 [  30  433  161   91 1578]]
0.48207628923719215
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.30      0.44      0.36       166
           p       0.33      0.43      0.37       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.677 | Rec. 0.695 | F1 0.482 | BEST F1: 0.490 57

Epoch:   60 2022-09-04 15:13:59.331540
[[ 4748     0     0     0     0]
 [    0 16364     4     0     0]
 [    0     0 18810     1     0]
 [    0     0     0  5325     0]
 [    0     0     1     1 16490]]
0.9989551263407126
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 415   64   39  101   14]
 [  75 1659  213   18  344]
 [  66  250 1709   77  247]
 [ 116   13   32  486   44]
 [  24  437  175   88 1569]]
0.48863126454370054
              precision    recall  f1-score   support

           a       0.69      0.78      0.73       841
           c       0.30      0.43      0.36       166
           p       0.33      0.44      0.38       171

   micro avg       0.56      0.68      0.62      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.58      0.68      0.63      1178

EVAL:   Pre. 0.682 | Rec. 0.698 | F1 0.489 | BEST F1: 0.490 57

Epoch:   61 2022-09-04 15:15:10.251325
[[ 4748     0     0     0     0]
 [    1 16363     4     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     2     1 16489]]
0.9987962444463842
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 421   57   37  107   11]
 [  87 1635  216   19  352]
 [  75  239 1719   87  229]
 [ 121   13   31  487   39]
 [  28  440  177   94 1554]]
0.48264367457133966
              precision    recall  f1-score   support

           a       0.67      0.79      0.72       841
           c       0.30      0.43      0.35       166
           p       0.32      0.44      0.37       171

   micro avg       0.55      0.69      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.69      0.62      1178

EVAL:   Pre. 0.675 | Rec. 0.697 | F1 0.483 | BEST F1: 0.490 57

Epoch:   62 2022-09-04 15:16:22.133978
[[ 4748     0     0     0     0]
 [    0 16364     4     0     0]
 [    0     0 18810     0     1]
 [    0     0     0  5324     1]
 [    0     0     1     0 16491]]
0.9990077939553963
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 399   67   39  110   18]
 [  73 1607  219   19  391]
 [  64  232 1701   82  270]
 [  92   12   29  502   56]
 [  22  384  161   85 1641]]
0.48364294859509344
              precision    recall  f1-score   support

           a       0.68      0.76      0.72       841
           c       0.30      0.43      0.35       166
           p       0.33      0.45      0.38       171

   micro avg       0.56      0.67      0.61      1178
   macro avg       0.44      0.55      0.48      1178
weighted avg       0.57      0.67      0.62      1178

EVAL:   Pre. 0.685 | Rec. 0.699 | F1 0.484 | BEST F1: 0.490 57

Epoch:   63 2022-09-04 15:17:32.814991
[[ 4748     0     0     0     0]
 [    0 16366     2     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5324     1]
 [    0     0     1     0 16491]]
0.9994093969809642
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 385   58   39  128   23]
 [  74 1539  225   22  449]
 [  56  211 1721   91  270]
 [  83   10   35  517   46]
 [  20  356  172   96 1649]]
0.47751428336326995
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.30      0.41      0.34       166
           p       0.31      0.46      0.37       171

   micro avg       0.55      0.67      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.67      0.61      1178

EVAL:   Pre. 0.680 | Rec. 0.695 | F1 0.478 | BEST F1: 0.490 57

Epoch:   64 2022-09-04 15:18:44.132341
[[ 4748     0     0     0     0]
 [    1 16366     1     0     0]
 [    0     1 18810     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9991107257772205
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 403   50   37  127   16]
 [  84 1594  188   22  421]
 [  69  237 1691   84  268]
 [  90   10   27  516   48]
 [  22  374  149   99 1649]]
0.4838155491875405
              precision    recall  f1-score   support

           a       0.66      0.78      0.72       841
           c       0.30      0.44      0.36       166
           p       0.32      0.46      0.38       171

   micro avg       0.55      0.69      0.61      1178
   macro avg       0.43      0.56      0.48      1178
weighted avg       0.56      0.69      0.62      1178

EVAL:   Pre. 0.682 | Rec. 0.703 | F1 0.484 | BEST F1: 0.490 57

Epoch:   65 2022-09-04 15:19:54.596031
[[ 4748     0     0     0     0]
 [    0 16366     2     0     0]
 [    0     2 18809     0     0]
 [    0     0     0  5324     1]
 [    0     0     1     0 16491]]
0.9988647346715961
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 388   52   40  131   22]
 [  80 1556  212   24  437]
 [  62  224 1704   89  270]
 [  89    9   30  512   51]
 [  23  360  166   97 1647]]
0.4776549141567173
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.31      0.42      0.36       166
           p       0.30      0.44      0.36       171

   micro avg       0.55      0.67      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.67      0.61      1178

EVAL:   Pre. 0.676 | Rec. 0.694 | F1 0.478 | BEST F1: 0.490 57

Epoch:   66 2022-09-04 15:21:06.870472
[[ 4748     0     0     0     0]
 [    0 16364     4     0     0]
 [    0     1 18810     0     0]
 [    0     0     0  5324     1]
 [    0     0     1     0 16491]]
0.9990011782513418
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 413   60   43  105   12]
 [  78 1627  235   19  350]
 [  67  237 1711   81  253]
 [ 113   10   32  494   42]
 [  28  418  163   95 1589]]
0.48211830974946807
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.30      0.42      0.35       166
           p       0.33      0.43      0.37       171

   micro avg       0.56      0.67      0.61      1178
   macro avg       0.44      0.54      0.48      1178
weighted avg       0.57      0.67      0.62      1178

EVAL:   Pre. 0.679 | Rec. 0.699 | F1 0.482 | BEST F1: 0.490 57

Epoch:   67 2022-09-04 15:22:22.355257
[[ 4748     0     0     0     0]
 [    0 16363     5     0     0]
 [    0     1 18810     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9990538458660255
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 417   55   40  107   14]
 [  83 1619  228   19  360]
 [  69  243 1716   84  237]
 [ 110   13   34  495   39]
 [  25  422  174   96 1576]]
0.47868224518301733
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.30      0.42      0.35       166
           p       0.33      0.43      0.37       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.54      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.678 | Rec. 0.699 | F1 0.479 | BEST F1: 0.490 57

Epoch:   68 2022-09-04 15:23:33.868242
[[ 4748     0     0     0     0]
 [    0 16367     1     0     0]
 [    0     1 18809     0     1]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9989241291912959
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 406   51   41  120   15]
 [  80 1590  227   20  392]
 [  60  223 1711   90  265]
 [  91    9   34  518   39]
 [  20  372  161  100 1640]]
0.4858210441135112
              precision    recall  f1-score   support

           a       0.68      0.78      0.73       841
           c       0.31      0.43      0.36       166
           p       0.31      0.46      0.37       171

   micro avg       0.55      0.69      0.61      1178
   macro avg       0.43      0.56      0.49      1178
weighted avg       0.57      0.69      0.62      1178

EVAL:   Pre. 0.684 | Rec. 0.705 | F1 0.486 | BEST F1: 0.490 57

Epoch:   69 2022-09-04 15:24:44.430312
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     2 18809     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9991897334409638
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 417   58   42  103   13]
 [  82 1653  229   19  326]
 [  67  244 1723   78  237]
 [ 118   12   33  485   43]
 [  22  425  181   94 1571]]
0.47962352678573433
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.30      0.43      0.35       166
           p       0.32      0.44      0.37       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.680 | Rec. 0.699 | F1 0.480 | BEST F1: 0.490 57

Epoch:   70 2022-09-04 15:25:55.651402
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     1 18810     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9994620645956479
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 416   64   39   99   15]
 [  80 1688  210   18  313]
 [  73  267 1686   76  247]
 [ 117   11   29  488   46]
 [  24  443  163   88 1575]]
0.4754222680188578
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.30      0.43      0.35       166
           p       0.31      0.42      0.35       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.42      0.54      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.700 | F1 0.475 | BEST F1: 0.490 57

Epoch:   71 2022-09-04 15:27:06.732096
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     1 18810     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9994620645956479
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 397   56   40  121   19]
 [  76 1594  225   20  394]
 [  61  213 1729   88  258]
 [  89    9   33  514   46]
 [  20  367  167   96 1643]]
0.4816828206208738
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.31      0.42      0.36       166
           p       0.31      0.45      0.37       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.685 | Rec. 0.703 | F1 0.482 | BEST F1: 0.490 57

Epoch:   72 2022-09-04 15:28:17.497891
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 411   55   40  111   16]
 [  80 1632  214   18  365]
 [  71  237 1691   88  262]
 [  98   12   27  508   46]
 [  21  393  149   95 1635]]
0.4929743184205629
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.32      0.45      0.38       166
           p       0.33      0.46      0.38       171

   micro avg       0.56      0.69      0.61      1178
   macro avg       0.44      0.56      0.49      1178
weighted avg       0.57      0.69      0.62      1178

EVAL:   Pre. 0.685 | Rec. 0.705 | F1 0.493 | BEST F1: 0.490 57
[[ 847  125   90  231   27]
 [ 160 3143  491   48  889]
 [ 136  595 3582  207  687]
 [ 276   36   80 1069   96]
 [  46  880  385  148 3277]]
0.484620534681481
              precision    recall  f1-score   support

           a       0.69      0.77      0.73      1829
           c       0.30      0.43      0.36       352
           p       0.31      0.46      0.37       345

   micro avg       0.56      0.68      0.62      2526
   macro avg       0.43      0.55      0.48      2526
weighted avg       0.58      0.68      0.63      2526

TEST:   Pre. 0.659 | Rec. 0.674 | F1 0.485

Epoch:   73 2022-09-04 15:29:52.584935
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 407   59   42  110   15]
 [  75 1619  243   19  353]
 [  65  239 1715   84  246]
 [  99   10   31  506   45]
 [  24  399  173   92 1605]]
0.4764520225607645
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.30      0.43      0.35       166
           p       0.30      0.43      0.36       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.42      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.701 | F1 0.476 | BEST F1: 0.493 72

Epoch:   74 2022-09-04 15:31:03.970887
[[ 4748     0     0     0     0]
 [    0 16367     1     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9994620645956479
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 398   60   41  116   18]
 [  75 1595  235   20  384]
 [  55  213 1733   87  261]
 [  92   10   35  510   44]
 [  21  387  176   91 1618]]
0.4932758695389953
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.33      0.45      0.38       166
           p       0.33      0.45      0.38       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.45      0.55      0.49      1178
weighted avg       0.58      0.68      0.62      1178

EVAL:   Pre. 0.684 | Rec. 0.700 | F1 0.493 | BEST F1: 0.493 72
[[ 802  137  104  249   28]
 [ 146 3027  575   47  936]
 [ 111  530 3706  193  667]
 [ 266   38   93 1061   99]
 [  35  842  435  150 3274]]
0.4847063235006048
              precision    recall  f1-score   support

           a       0.69      0.76      0.72      1829
           c       0.30      0.43      0.35       352
           p       0.32      0.47      0.38       345

   micro avg       0.56      0.67      0.61      2526
   macro avg       0.44      0.55      0.48      2526
weighted avg       0.59      0.67      0.62      2526

TEST:   Pre. 0.657 | Rec. 0.666 | F1 0.485

Epoch:   75 2022-09-04 15:32:39.042973
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     1 16490]]
0.9996817281356484
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 410   63   34  113   13]
 [  79 1660  185   19  366]
 [  73  264 1644   93  275]
 [ 105   12   24  510   40]
 [  23  419  132   99 1620]]
0.48247211505625826
              precision    recall  f1-score   support

           a       0.66      0.79      0.72       841
           c       0.30      0.44      0.36       166
           p       0.32      0.44      0.37       171

   micro avg       0.55      0.69      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.56      0.69      0.62      1178

EVAL:   Pre. 0.681 | Rec. 0.702 | F1 0.482 | BEST F1: 0.493 74

Epoch:   76 2022-09-04 15:33:48.963003
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 401   58   42  113   19]
 [  79 1597  223   19  391]
 [  58  212 1744   80  255]
 [  94    9   37  512   39]
 [  22  387  184   91 1609]]
0.48176285914398886
              precision    recall  f1-score   support

           a       0.68      0.77      0.72       841
           c       0.31      0.42      0.35       166
           p       0.32      0.44      0.37       171

   micro avg       0.56      0.67      0.61      1178
   macro avg       0.43      0.54      0.48      1178
weighted avg       0.57      0.67      0.62      1178

EVAL:   Pre. 0.685 | Rec. 0.702 | F1 0.482 | BEST F1: 0.493 74

Epoch:   77 2022-09-04 15:34:58.688961
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 420   59   38  103   13]
 [  80 1650  223   19  337]
 [  75  246 1712   75  241]
 [ 129   12   30  481   39]
 [  26  435  167   94 1571]]
0.47952244703075125
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.30      0.45      0.36       166
           p       0.30      0.42      0.35       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.678 | Rec. 0.698 | F1 0.480 | BEST F1: 0.493 74

Epoch:   78 2022-09-04 15:36:08.512790
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 387   55   37  132   22]
 [  71 1563  216   23  436]
 [  61  216 1711   90  271]
 [  91   10   28  518   44]
 [  19  360  156  100 1658]]
0.4824671590627523
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.31      0.42      0.35       166
           p       0.31      0.46      0.37       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.681 | Rec. 0.698 | F1 0.482 | BEST F1: 0.493 74

Epoch:   79 2022-09-04 15:37:18.470661
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 392   60   37  121   23]
 [  70 1606  211   20  402]
 [  64  232 1700   80  273]
 [  91   11   28  514   47]
 [  19  377  155   89 1653]]
0.487868712189311
              precision    recall  f1-score   support

           a       0.68      0.78      0.73       841
           c       0.31      0.42      0.36       166
           p       0.33      0.45      0.38       171

   micro avg       0.56      0.68      0.62      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.58      0.68      0.62      1178

EVAL:   Pre. 0.686 | Rec. 0.701 | F1 0.488 | BEST F1: 0.493 74

Epoch:   80 2022-09-04 15:38:28.144926
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     1 16491]]
0.9999473323853163
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 408   60   40  111   14]
 [  77 1620  227   20  365]
 [  64  236 1708   85  256]
 [ 101   12   28  509   41]
 [  23  413  166  102 1589]]
0.48229955799288043
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.31      0.44      0.37       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.681 | Rec. 0.701 | F1 0.482 | BEST F1: 0.493 74

Epoch:   81 2022-09-04 15:39:37.831087
[[ 4748     0     0     0     0]
 [    0 16367     1     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9994620645956479
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 403   58   37  113   22]
 [  74 1622  215   19  379]
 [  62  233 1697   82  275]
 [  99   11   29  504   48]
 [  19  409  153   90 1622]]
0.4834915790048752
              precision    recall  f1-score   support

           a       0.68      0.77      0.72       841
           c       0.31      0.43      0.36       166
           p       0.32      0.43      0.37       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.44      0.54      0.48      1178
weighted avg       0.58      0.68      0.62      1178

EVAL:   Pre. 0.684 | Rec. 0.700 | F1 0.483 | BEST F1: 0.493 74

Epoch:   82 2022-09-04 15:40:47.867605
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 420   61   36  104   12]
 [  79 1682  199   18  331]
 [  74  263 1684   77  251]
 [ 136   13   26  473   43]
 [  24  470  152   93 1554]]
0.48252326507139104
              precision    recall  f1-score   support

           a       0.68      0.79      0.73       841
           c       0.30      0.45      0.36       166
           p       0.32      0.42      0.36       171

   micro avg       0.56      0.69      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.69      0.62      1178

EVAL:   Pre. 0.676 | Rec. 0.694 | F1 0.483 | BEST F1: 0.493 74

Epoch:   83 2022-09-04 15:42:00.006554
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 407   57   38  116   15]
 [  79 1631  205   19  375]
 [  63  236 1703   86  261]
 [  98   10   29  511   43]
 [  21  411  160   99 1602]]
0.4899863157047412
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.33      0.46      0.39       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.69      0.62      1178
   macro avg       0.44      0.56      0.49      1178
weighted avg       0.57      0.69      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.702 | F1 0.490 | BEST F1: 0.493 74

Epoch:   84 2022-09-04 15:43:10.786730
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 406   57   37  116   17]
 [  80 1615  211   20  383]
 [  68  235 1684   91  271]
 [  98   10   27  511   45]
 [  23  392  156  100 1622]]
0.480365783546008
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.31      0.43      0.36       166
           p       0.31      0.44      0.36       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.680 | Rec. 0.701 | F1 0.480 | BEST F1: 0.493 74

Epoch:   85 2022-09-04 15:44:24.520462
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 405   54   39  117   18]
 [  88 1597  232   18  374]
 [  63  224 1715   89  258]
 [  97   10   30  511   43]
 [  21  381  168  103 1620]]
0.48170941039053367
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.31      0.42      0.36       166
           p       0.32      0.44      0.37       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.680 | Rec. 0.702 | F1 0.482 | BEST F1: 0.493 74

Epoch:   86 2022-09-04 15:45:36.507546
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 413   67   37  102   14]
 [  77 1654  208   19  351]
 [  70  244 1693   85  257]
 [ 116   11   30  491   43]
 [  23  426  157   91 1596]]
0.4841595902201665
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.31      0.44      0.36       166
           p       0.32      0.43      0.37       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.681 | Rec. 0.699 | F1 0.484 | BEST F1: 0.493 74

Epoch:   87 2022-09-04 15:46:46.605768
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 409   67   38  104   15]
 [  74 1636  222   19  358]
 [  63  243 1708   86  249]
 [ 102   11   31  505   42]
 [  21  413  162   98 1599]]
0.4844834721989613
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.31      0.45      0.37       166
           p       0.32      0.44      0.37       171

   micro avg       0.55      0.68      0.61      1178
   macro avg       0.43      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.684 | Rec. 0.702 | F1 0.484 | BEST F1: 0.493 74

Epoch:   88 2022-09-04 15:47:57.066404
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9997343957503321
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 409   62   40  106   16]
 [  79 1624  218   19  369]
 [  62  235 1705   85  262]
 [  97   10   31  507   46]
 [  20  401  161   92 1619]]
0.4850577303413888
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.32      0.45      0.37       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.43      0.55      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.686 | Rec. 0.703 | F1 0.485 | BEST F1: 0.493 74

Epoch:   89 2022-09-04 15:49:06.642230
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 407   58   43  105   20]
 [  77 1611  232   19  370]
 [  61  222 1723   84  259]
 [  95   10   31  511   44]
 [  21  386  165   93 1628]]
0.4870710189972714
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.31      0.43      0.36       166
           p       0.33      0.45      0.38       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.687 | Rec. 0.705 | F1 0.487 | BEST F1: 0.493 74

Epoch:   90 2022-09-04 15:50:15.848520
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 410   60   40  108   15]
 [  77 1628  224   19  361]
 [  62  235 1710   87  255]
 [ 101   11   31  507   41]
 [  24  404  163   98 1604]]
0.48912350896779583
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.32      0.45      0.38       166
           p       0.32      0.44      0.37       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.703 | F1 0.489 | BEST F1: 0.493 74

Epoch:   91 2022-09-04 15:51:25.666546
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 413   63   39  103   15]
 [  76 1632  221   19  361]
 [  62  235 1712   85  255]
 [ 104   10   31  505   41]
 [  23  413  164   94 1599]]
0.48609630859392716
              precision    recall  f1-score   support

           a       0.68      0.78      0.72       841
           c       0.32      0.45      0.37       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.685 | Rec. 0.703 | F1 0.486 | BEST F1: 0.493 74

Epoch:   92 2022-09-04 15:52:35.715978
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 410   60   39  106   18]
 [  77 1625  219   19  369]
 [  63  235 1705   85  261]
 [ 103   10   30  506   42]
 [  22  406  162   95 1608]]
0.4849331450316672
              precision    recall  f1-score   support

           a       0.67      0.78      0.72       841
           c       0.32      0.45      0.37       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.44      0.55      0.48      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.684 | Rec. 0.702 | F1 0.485 | BEST F1: 0.493 74

Epoch:   93 2022-09-04 15:53:46.955546
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 409   58   39  109   18]
 [  76 1620  212   19  382]
 [  66  234 1698   86  265]
 [  97   10   30  511   43]
 [  21  392  160   95 1625]]
0.49112341045115465
              precision    recall  f1-score   support

           a       0.68      0.78      0.72       841
           c       0.33      0.46      0.39       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.62      1178
   macro avg       0.44      0.56      0.49      1178
weighted avg       0.58      0.68      0.62      1178

EVAL:   Pre. 0.685 | Rec. 0.704 | F1 0.491 | BEST F1: 0.493 74

Epoch:   94 2022-09-04 15:54:58.076987
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 409   55   39  112   18]
 [  80 1605  216   19  389]
 [  65  229 1702   86  267]
 [  92   10   30  517   42]
 [  21  381  160   98 1633]]
0.49258512457060016
              precision    recall  f1-score   support

           a       0.68      0.78      0.72       841
           c       0.33      0.44      0.38       166
           p       0.33      0.44      0.38       171

   micro avg       0.57      0.68      0.62      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.58      0.68      0.62      1178

EVAL:   Pre. 0.685 | Rec. 0.705 | F1 0.493 | BEST F1: 0.493 74

Epoch:   95 2022-09-04 15:56:11.079166
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 414   59   41  105   14]
 [  78 1624  222   19  366]
 [  66  237 1700   87  259]
 [ 105   10   30  505   41]
 [  26  407  161   96 1603]]
0.48643265796328783
              precision    recall  f1-score   support

           a       0.68      0.78      0.72       841
           c       0.32      0.45      0.37       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.682 | Rec. 0.702 | F1 0.486 | BEST F1: 0.493 74

Epoch:   96 2022-09-04 15:57:22.703303
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 411   58   41  106   17]
 [  76 1622  223   19  369]
 [  66  234 1701   87  261]
 [ 102   10   30  508   41]
 [  24  400  162   97 1610]]
0.4862899921023935
              precision    recall  f1-score   support

           a       0.68      0.78      0.72       841
           c       0.32      0.45      0.37       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.703 | F1 0.486 | BEST F1: 0.493 74

Epoch:   97 2022-09-04 15:58:32.938900
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 411   57   40  108   17]
 [  77 1623  219   19  371]
 [  66  236 1699   87  261]
 [ 101   10   30  509   41]
 [  24  399  161   97 1612]]
0.4875976517342087
              precision    recall  f1-score   support

           a       0.68      0.78      0.72       841
           c       0.32      0.45      0.38       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.44      0.55      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.703 | F1 0.488 | BEST F1: 0.493 74

Epoch:   98 2022-09-04 15:59:43.713135
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 411   57   40  108   17]
 [  76 1622  219   19  373]
 [  66  235 1699   87  262]
 [ 100   10   30  510   41]
 [  24  398  160   97 1614]]
0.4882587379111471
              precision    recall  f1-score   support

           a       0.68      0.78      0.73       841
           c       0.32      0.45      0.38       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.62      1178
   macro avg       0.44      0.56      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.703 | F1 0.488 | BEST F1: 0.493 74

Epoch:   99 2022-09-04 16:00:53.063057
[[ 4748     0     0     0     0]
 [    0 16368     0     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     0     0 16492]]
1.0
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 1.000
[[ 411   57   40  108   17]
 [  76 1622  219   19  373]
 [  66  235 1699   87  262]
 [ 100   10   30  510   41]
 [  24  398  160   97 1614]]
0.4882587379111471
              precision    recall  f1-score   support

           a       0.68      0.78      0.73       841
           c       0.32      0.45      0.38       166
           p       0.31      0.43      0.36       171

   micro avg       0.56      0.68      0.62      1178
   macro avg       0.44      0.56      0.49      1178
weighted avg       0.57      0.68      0.62      1178

EVAL:   Pre. 0.683 | Rec. 0.703 | F1 0.488 | BEST F1: 0.493 74

Some weights of the model checkpoint at ../model_base/ were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

Inference:

[[ 4748     0     0     0     0]
 [    0 16367     1     0     0]
 [    0     0 18811     0     0]
 [    0     0     0  5325     0]
 [    0     0     1     0 16491]]
0.9994620645956479
              precision    recall  f1-score   support

           a       1.00      1.00      1.00      6329
           c       1.00      1.00      1.00      1224
           p       1.00      1.00      1.00      1255

   micro avg       1.00      1.00      1.00      8808
   macro avg       1.00      1.00      1.00      8808
weighted avg       1.00      1.00      1.00      8808

TRAIN:  Pre. 1.000 | Rec. 1.000 | F1 0.999
[[ 398   60   41  116   18]
 [  75 1595  235   20  384]
 [  55  213 1733   87  261]
 [  92   10   35  510   44]
 [  21  387  176   91 1618]]
0.4932758695389953
              precision    recall  f1-score   support

           a       0.67      0.77      0.72       841
           c       0.33      0.45      0.38       166
           p       0.33      0.45      0.38       171

   micro avg       0.56      0.68      0.61      1178
   macro avg       0.45      0.55      0.49      1178
weighted avg       0.58      0.68      0.62      1178

EVAL:   Pre. 0.684 | Rec. 0.700 | F1 0.493
[[ 802  137  104  249   28]
 [ 146 3027  575   47  936]
 [ 111  530 3706  193  667]
 [ 266   38   93 1061   99]
 [  35  842  435  150 3274]]
0.4847063235006048
              precision    recall  f1-score   support

           a       0.69      0.76      0.72      1829
           c       0.30      0.43      0.35       352
           p       0.32      0.47      0.38       345

   micro avg       0.56      0.67      0.61      2526
   macro avg       0.44      0.55      0.48      2526
weighted avg       0.59      0.67      0.62      2526

TEST:   Pre. 0.657 | Rec. 0.666 | F1 0.485

Process finished with exit code 0
